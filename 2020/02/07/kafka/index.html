<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://vicyor.gitee.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://vicyor.gitee.io/2020/02/07/kafka/index.html">
<meta property="og:site_name" content="Vicyor">
<meta property="og:description" content="Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/consumer-group.jpg">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/kafka-partition.jpg">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/produce-record.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/topic-consumer-group.png">
<meta property="article:published_time" content="2020-02-07T01:50:25.000Z">
<meta property="article:modified_time" content="2020-08-24T01:55:02.412Z">
<meta property="article:author" content="vicyor">
<meta property="article:tag" content="java">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="messaging">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://vicyor.gitee.io/2020/02/07/kafka/consumer-group.jpg">

<link rel="canonical" href="http://vicyor.gitee.io/2020/02/07/kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>kafka | Vicyor</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Vicyor</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">46</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">48</span></a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://vicyor.gitee.io/2020/02/07/kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="vicyor">
      <meta itemprop="description" content="大路且慢慢,咱一步一步走完.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vicyor">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-07 09:50:25" itemprop="dateCreated datePublished" datetime="2020-02-07T09:50:25+08:00">2020-02-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-08-24 09:55:02" itemprop="dateModified" datetime="2020-08-24T09:55:02+08:00">2020-08-24</time>
              </span>

          
            <span id="/2020/02/07/kafka/" class="post-meta-item leancloud_visitors" data-flag-title="kafka" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/02/07/kafka/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/02/07/kafka/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>28k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>26 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。</p>
<a id="more"></a>
<h2 id="Kafka基本概念"><a href="#Kafka基本概念" class="headerlink" title="Kafka基本概念"></a>Kafka基本概念</h2><h3 id="发布和订阅系统"><a href="#发布和订阅系统" class="headerlink" title="发布和订阅系统"></a>发布和订阅系统</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">发布订阅系统:</span><br><span class="line">    消息的发布者不会直接把消息发送给接受者,发布者以某种方式对消息进行分类并发送到服务器,接受者从服务器订阅它们,以便接收特定类型的消息.</span><br></pre></td></tr></table></figure>
<h3 id="kafka简介"><a href="#kafka简介" class="headerlink" title="kafka简介"></a>kafka简介</h3><h4 id="消息和批次"><a href="#消息和批次" class="headerlink" title="消息和批次"></a>消息和批次</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.消息(message)  ---&gt;   kafka的数据单元</span><br><span class="line">  消息物理上是kafka服务器存储文件中的一个数据行,kafka服务器根据消息的键将消息写入不同的分区.</span><br><span class="line">2.批次(batch)是指一组消息.</span><br><span class="line">  批次可以减少网络传输次数,减少网络开销.</span><br></pre></td></tr></table></figure>
<h4 id="模式-schema"><a href="#模式-schema" class="headerlink" title="模式-schema"></a>模式-schema</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.kafka没有消息schema,消息存储就是简单byte[].</span><br><span class="line">2.消息模式.</span><br><span class="line">  1.json.</span><br><span class="line">  2.xml.</span><br><span class="line">  3.avro.</span><br></pre></td></tr></table></figure>
<h4 id="主题和分区"><a href="#主题和分区" class="headerlink" title="主题和分区"></a>主题和分区</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.kafka的消息通过主题进行分类,主题就像数据库的表,或者文件系统中的目录.</span><br><span class="line">2.主题(topic)可以被分为若干个分区.</span><br><span class="line">  1.一个主题的分区分布在不同的kafka服务器(broker)上.</span><br><span class="line">        消息以追加(append)的方式写入分区,</span><br><span class="line">        读取是以先入先出(先写入先读取,不是先发送先读取)的顺序读取.</span><br><span class="line">  2.kafka通过分区来实现数据冗余和伸缩性.分区可以分布在不同的服务器上.</span><br><span class="line">        冗余 --&gt; 通过副本.</span><br><span class="line">        伸缩 --&gt; 通过分区.</span><br></pre></td></tr></table></figure>
<h4 id="生产者和消费者"><a href="#生产者和消费者" class="headerlink" title="生产者和消费者"></a>生产者和消费者</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.kafka的客户端就是kafka的用户,分为生产者和消费者.</span><br><span class="line">2.kafka客户端API --&gt; Kafka Connect API 和 Kafka Streams.</span><br><span class="line">3.生产者默认情况下把消息均衡地分布(publish)到主题的消息分区上,而并不会关心消息会被写到哪个分区上.</span><br><span class="line">4.消费者读取消息,消费者订阅(subscribe)一个或多个主题,并且按照消息生成的顺序读取它们.</span><br><span class="line">5.偏移量(offset)是一种元数据,是一个不断递增的整数值,</span><br><span class="line">  在分区中,每个消息的偏移量都是唯一的.</span><br><span class="line">    消费者把每个分区最后读取的消息偏移量都保存在ZooKeeper(老版消费者API)或kafka(新版消费者API)上.</span><br><span class="line">    所以当消费者关闭或重启时,它的读取状态不会丢失(指的是同一个消费者群组消费过的消息不会被重复消费).</span><br><span class="line">6.消费者群组:消费者是消费者群组的一部分,会有一个或多个消费者共同读取一个主题.</span><br><span class="line">    群组与群组之间互相不影响.  </span><br><span class="line">    一个群组中的消费者不会重复消费一个topic中的消息.</span><br><span class="line">    一个群组中的消费者消费不同的topic的分区.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/consumer-group.jpg" alt></p>
<h4 id="broker和集群"><a href="#broker和集群" class="headerlink" title="broker和集群"></a>broker和集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">broker ---&gt; 一个独立的kafka服务器.</span><br><span class="line">1.broker接收来自生产者的消息,为消息设置偏移量,并提交消息到磁盘保存.</span><br><span class="line">2.broker为消费者提供服务,对读取分区的请求做出响应,返回已经提交到磁盘上的信息.</span><br><span class="line">3.根据硬件和其性能,单个broker可以轻松的处理数千个分区以及每秒百万级的消息量.</span><br><span class="line">4.broker集群会有一个broker充当集群控制器(master,自动的从集群的活跃成员中选举出来)的角色.</span><br><span class="line">  控制器负责管理工作,包括将分区分配给broker和监控broker.</span><br><span class="line">5.对于分区而言,分区和它的备份分区也有leader和follower的关系.</span><br><span class="line">6.一个分区可以分配给多个broker,这种复制机制为分区提供了消息冗余.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/kafka-partition.jpg" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">7.保留信息是kafka的一个重要特性.</span><br><span class="line">  Kafka broker 默认的 消息保留与时间和大小有关,当消息总大小,时间达到一定上线时候,旧消息就会删除.</span><br></pre></td></tr></table></figure>
<h3 id="为什么选择kafka"><a href="#为什么选择kafka" class="headerlink" title="为什么选择kafka"></a>为什么选择kafka</h3><h4 id="多生产者"><a href="#多生产者" class="headerlink" title="多生产者"></a>多生产者</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka 适合从多个前端系统收集数据,并以统一的格式对外提供数据.</span><br></pre></td></tr></table></figure>
<h4 id="多消费者"><a href="#多消费者" class="headerlink" title="多消费者"></a>多消费者</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka支持多消费者从一个单独的消息流上读取数据.</span><br><span class="line">消费者之间互不影响.</span><br><span class="line">ps: 消费者组与消费者组之间共享一个topic(广播).</span><br><span class="line">    消费者组之内的各个消费者分割一个topic.</span><br></pre></td></tr></table></figure>
<h4 id="基于磁盘的数据存储-非实时处理和消息不丢失"><a href="#基于磁盘的数据存储-非实时处理和消息不丢失" class="headerlink" title="基于磁盘的数据存储-非实时处理和消息不丢失"></a>基于磁盘的数据存储-非实时处理和消息不丢失</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.持久化可以实现消费者非实时地读取消息,归功于kafka的数据保留特性.   </span><br><span class="line">2.每个topic可以设置单独的保留规则.满足不同消费者的需求,各个主体可以保留不同数量的消息.</span><br><span class="line">3.消费者可能因为处理慢,流量高峰,无法及时读取消息,持久化可以保证消息不会丢失.</span><br></pre></td></tr></table></figure>
<h4 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以横向扩展broker服务器.实现高可用,高并发,高性能.</span><br></pre></td></tr></table></figure>
<h3 id="数据生态系统"><a href="#数据生态系统" class="headerlink" title="数据生态系统"></a>数据生态系统</h3><h4 id="kafka使用场景"><a href="#kafka使用场景" class="headerlink" title="kafka使用场景"></a>kafka使用场景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.活动追踪.  网站前端和用户的交互,kafka收集数据,为机器学习系统提供数据.</span><br><span class="line">2.传递信息.  邮件.</span><br><span class="line">3.度量指标和日志. </span><br><span class="line">4.异步通信.</span><br><span class="line">5.流处理.   计算.</span><br></pre></td></tr></table></figure>
<h2 id="第二章-kafka的安装"><a href="#第二章-kafka的安装" class="headerlink" title="第二章  kafka的安装"></a>第二章  kafka的安装</h2><h3 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zookeeper是java写的,运行需要jvm.</span><br><span class="line">kafka是scala写的.</span><br></pre></td></tr></table></figure>
<h3 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zookeeper主要存储broker和topic的元数据.</span><br></pre></td></tr></table></figure>
<h3 id="安装kafka"><a href="#安装kafka" class="headerlink" title="安装kafka"></a>安装kafka</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;kafka&#x2F;2.4.0&#x2F;kafka_2.11-2.4.0.tgz </span><br><span class="line">2.tar -zxf kafka_2.11-2.4.0.tgz </span><br><span class="line">  mv kafka_2.11-2.4.0 &#x2F;usr&#x2F;local&#x2F;kafka</span><br><span class="line">3.mkdir &#x2F;tmp&#x2F;kafka-logs   &#x2F;&#x2F;创建日志目录</span><br><span class="line">4.export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_51</span><br><span class="line">5.启动</span><br><span class="line">  kafka-server-start.sh -daemon  &#x2F;usr&#x2F;local&#x2F;kafka&#x2F;config&#x2F;server.properties (守护线程启动)</span><br><span class="line">ps:若zk报错,可以清空&#x2F;tmp目录下的数据</span><br><span class="line">   或使用内嵌的zookeeper</span><br><span class="line">   内嵌zk启动.   zookeeper-server-start.sh config&#x2F;zookeeper.properties</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">测试安装.</span><br><span class="line">1.创建一个测试主题,发布一些信息,然后读取它们.</span><br><span class="line">  --bootstrap-server 使用自带的zookeeper</span><br><span class="line">  1.创建一个测试主题.</span><br><span class="line">    kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test</span><br><span class="line">  2.查看测试主题.</span><br><span class="line">    kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class="line">  3.向主题发送一些信息.</span><br><span class="line">    kafka-console-producer.sh --broker-list localhost:9092 --topic test</span><br><span class="line">  4.消费者消费消息.</span><br><span class="line">    kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test</span><br></pre></td></tr></table></figure>
<h3 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h3><h4 id="常规配置"><a href="#常规配置" class="headerlink" title="常规配置"></a>常规配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">server.properties</span><br><span class="line">broker.id&#x3D;0       kafka服务器的标识符.</span><br><span class="line">port&#x3D;9092         默认9092.</span><br><span class="line">zookeeper.connect&#x3D;localhost:port&#x2F;kafka  broker元数据所存放的zookeeper路径.</span><br><span class="line">log.dirs&#x3D;&#x2F;tmp&#x2F;kafka   消息目录，kafka把所有的消息都保存在磁盘上.如果指定多个路径,broker会根据最少使用原则,把一个分区的日志片段保存在同一个路径下.</span><br><span class="line">num.recovery.thread.per.data.dir&#x3D;1</span><br><span class="line">  日志(日志是kafka数据的存储方式)的每个目录的恢复线程数,三种情况,kafka会使用该线程池处理日志片段(数据片段).</span><br><span class="line">     1.服务器正常启动,用于打开每个分区的日志片段.</span><br><span class="line">     2.服务器奔溃后重启,用于检查和截断每个分区的日志片段.</span><br><span class="line">     3.服务器正常关闭,用于关闭日志片段.</span><br><span class="line">auto.create.topics.enable&#x3D;true</span><br><span class="line">  默认情况下,kafka自动创建主题的几种情形. ps: 主题不存在,创建主题.</span><br><span class="line">      1.当一个生产者开始往主题写入消息时.</span><br><span class="line">      2.当一个消费者开始从主题读取消息时.</span><br><span class="line">      3.当任意一个客户端向主题发送元数据请求时.</span><br></pre></td></tr></table></figure>
<h4 id="topic的默认配置"><a href="#topic的默认配置" class="headerlink" title="topic的默认配置"></a>topic的默认配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num.partitions    自动创建主题的分区个数 ps:可以增加分区的个数,但不能降低分区的个数.分区的个数必须大于broker的个数.</span><br><span class="line">       topic吞吐量: ---&gt;  partitions * 消费者客户端的数量 (一个partition一个消费者)</span><br><span class="line">       consumerGroup  -&gt;  topic</span><br><span class="line">       consumerGroup&#39;s consumer -&gt; partition</span><br><span class="line">log.retention.ms  数据的保留时间,默认为168小时.</span><br><span class="line">log.retention.bytes 分区大小阈值，若分区已满，则不会存储新消息. 例: log.retention.bytes&#x3D;1GB,partitions&#x3D;8,则topic最多保留8GB</span><br><span class="line">log.segment.ms</span><br><span class="line">log.segment.bytes</span><br><span class="line">message.max.bytes  单个消息的大小,默认是100000即1MB(10^6).</span><br><span class="line">            当producer消息超过该大小,broker会拒收并返回错误信息.</span><br><span class="line">      ps:消息大小是指压缩后的大小,压缩前可以大于1MB.</span><br></pre></td></tr></table></figure>
<h3 id="操作系统调优"><a href="#操作系统调优" class="headerlink" title="操作系统调优"></a>操作系统调优</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">大多数linux发行版内核默认的调优参数配置已经满足大多数应用程序的运行需求,不过还是可以通过调整一些参数来进一步提升kafka的性能.</span><br><span class="line">这些参数主要与虚拟内存,网络子系统,存储日志片段的磁盘挂载点.这些参数一般都存在&#x2F;etc&#x2F;sysctl.conf中.</span><br></pre></td></tr></table></figure>
<h4 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.Linux的虚拟内存会根据系统的工作负荷进行自动调整.</span><br><span class="line">2.可以调整 交换分区的处理方式 和 内存脏页.</span><br><span class="line">3.对于大多数依赖吞吐量的应用程序来说,应该尽量避免内存交换.</span><br><span class="line">  内存页和磁盘之间的交换对kafka各方面性能有着重大影响.</span><br><span class="line">  vm.swappiness swap的大小设置的小一点.</span><br><span class="line">  vm.dirty_background_ratio 系统内存的百分比.与脏页的数量有关.</span><br><span class="line">  脏页:linux内核的概念,因为硬盘的读写速度赶不上内存的读写速度.</span><br><span class="line">       系统把读写比较频繁的数据事先放到内存中,以提高读写速度,这叫做高速缓存.</span><br><span class="line">       linux以页作为高速缓存的单位,当进程修改了高速缓存的数据时,该页就被内核标记为脏页.</span><br><span class="line">       内核会在合适的时间,把脏页的数据写到磁盘上,以保持高速缓存中的数据和磁盘中的数据是一致的.</span><br></pre></td></tr></table></figure>
<h4 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.硬件设备和RAID磁盘阵列.</span><br><span class="line">2.文件系统. XFS文件系统.</span><br><span class="line">  对挂载点设置noatime参数,atime是指文件的访问时间(atime)属性,kafka不需要该属性,可以禁用掉它.</span><br><span class="line">  mount -o noatime &#x2F;dev&#x2F;sda  &#x2F;kafka&#x2F;log</span><br></pre></td></tr></table></figure>
<h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.socket读&#x2F;写缓冲区 大小调整.</span><br><span class="line">  net.core.wmem_default&#x2F;net.core.rmem_default   读写缓冲区的默认大小(128KB)</span><br><span class="line">  net.core.wmem_max&#x2F;net.core.rmem_max           读写缓冲区的最大值(2MB) </span><br><span class="line">2.TCP socket 读&#x2F;写缓冲区</span><br><span class="line">  net.ipv4.tcp_wmem&#x2F;net.ipv4.tcp_rmem           tcp读&#x2F;写缓存区的 最小值 默认值 最大值</span><br><span class="line">  例: net.ipv4.tcp_wem&#x3D; 4096 65536 2048000</span><br><span class="line">3.尽量调大一点,担保网络流量的爆发.</span><br></pre></td></tr></table></figure>
<h3 id="生产环境的注意事项"><a href="#生产环境的注意事项" class="headerlink" title="生产环境的注意事项"></a>生产环境的注意事项</h3><h4 id="垃圾回收选项"><a href="#垃圾回收选项" class="headerlink" title="垃圾回收选项"></a>垃圾回收选项</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.G1----&gt; Garbage First 总是回收最大价值的region.</span><br><span class="line">2.参数调整.</span><br><span class="line">  MaxGCPauseMills:                      每次垃圾回收默认的停顿时间(200ms).</span><br><span class="line">  InitiatingHeapOccupancyPerent:        G1垃圾回收之前可以使用的堆内存百分比(45%).</span><br><span class="line">3.kafka容易产生垃圾对象,尽量将参数调低一点,使垃圾回收频率大一点.</span><br><span class="line">4.Kafka默认使用了 ParllelNew + CMS</span><br><span class="line">  将其修改成G1.</span><br><span class="line">  export KAFKA_JVM_PERFORMANCE_OPTS&#x3D;&quot;-server -XX:+UseG1GC -XX:MaxGCPauseMillis&#x3D;20 -XX:InitiatingHeapOccupancyPercent&#x3D;35 -XX:+DisableExplicitGC -Djava.aut.headless&#x3D;true&quot;  </span><br><span class="line">  DisableExplicitGC  禁止运行时候显示的调用System.gc() ps:System.gc()会触发full gc;</span><br></pre></td></tr></table></figure>
<h2 id="第三章-kafka生产者"><a href="#第三章-kafka生产者" class="headerlink" title="第三章  kafka生产者"></a>第三章  kafka生产者</h2><h3 id="生产者概览"><a href="#生产者概览" class="headerlink" title="生产者概览"></a>生产者概览</h3><p><img src="/2020/02/07/kafka/produce-record.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.若ProducerRecord未指定分区,则分区器会根据key选择一个分区.</span><br><span class="line">2.获取分区后,生产者知道往哪个主题和分区发送这条记录.</span><br><span class="line">3.记录会被添加到一个批次(batch)中,这个批次的所有消息都会发到相同的一个主题和一个分区中.</span><br><span class="line">4.若消息成功写入kafka,会返回一个RecordMetaData对象,它包含了主题和分区信息,以及记录在分区里的偏移量.</span><br><span class="line">    写入失败,则会返回一个错误.生产者收到错误后会尝试重新发送消息,若还是失败,则会返回错误信息.</span><br></pre></td></tr></table></figure>
<h3 id="创建kafka生产者"><a href="#创建kafka生产者" class="headerlink" title="创建kafka生产者"></a>创建kafka生产者</h3><h4 id="kafka生产者的3个必须的属性"><a href="#kafka生产者的3个必须的属性" class="headerlink" title="kafka生产者的3个必须的属性"></a>kafka生产者的3个必须的属性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.servers   broker的地址清单,格式为host:port.</span><br><span class="line">key.serializer      实现了org.apache.kafka.common.serialization.Serializer接口的类</span><br><span class="line">value.serializer    实现了org.apache.kafka.common.serialization.Serializer接口的类</span><br></pre></td></tr></table></figure>
<h4 id="kafka生产者发送消息的三种方式"><a href="#kafka生产者发送消息的三种方式" class="headerlink" title="kafka生产者发送消息的三种方式"></a>kafka生产者发送消息的三种方式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.发送并忘记(fire-and-forgot).</span><br><span class="line">  大多数情况下,及使消息未到达,生产者也会重试,少数失败情况会抛出异常,不过发送并忘记不关心结果.</span><br><span class="line">2.同步发送(我觉得还是异步).</span><br><span class="line">  返回Future对象,通过get()方法获取结果.</span><br><span class="line">3.异步发送.</span><br><span class="line">  传入回调函数,服务器在返回响应时候调用该函数.</span><br></pre></td></tr></table></figure>
<h4 id="发送消息到kafka"><a href="#发送消息到kafka" class="headerlink" title="发送消息到kafka"></a>发送消息到kafka</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.send方法会发送ProducerRecord对象,并返回一个Future&lt;RecordMetadata&gt;对象.</span><br><span class="line">2.send发送的消息的键和值必须与其对应的key序列化器保持一致.</span><br><span class="line">  例如str   &lt; --- &gt;   StringSerializer </span><br><span class="line">  key -&gt; 并不是唯一的</span><br><span class="line">3.发送操作可能出现错误种类.</span><br><span class="line">  1.可重试错误.  无主(no leader)错误、连接错误、多次重试(客户端自动重试)失败后,服务器会收到一个重试异常.</span><br><span class="line">  2.不可重试错误. 消息太大等.</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Properties kafkaProps=<span class="keyword">new</span> Properties();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">()</span></span>&#123;</span><br><span class="line">        kafkaProps.put(<span class="string">"bootstrap.servers"</span>,<span class="string">"192.168.78.129:9092"</span>);</span><br><span class="line">        kafkaProps.put(<span class="string">"key.serializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        kafkaProps.put(<span class="string">"value.serialzier"</span>,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        producer=<span class="keyword">new</span> KafkaProducer(kafkaProps);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> KafkaProducer producer=<span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * fire-and-forget</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fireAndForgotSend</span><span class="params">(String key,String message,String topic)</span></span>&#123;</span><br><span class="line">        ProducerRecord&lt;String,String&gt;record=<span class="keyword">new</span> ProducerRecord(key,message,topic);</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 同步发送消息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RecordMetadata <span class="title">sendMessage</span><span class="params">(String key,String message,String topic)</span></span>&#123;</span><br><span class="line">        ProducerRecord&lt;String,String&gt;record=<span class="keyword">new</span> ProducerRecord(key,message,topic);</span><br><span class="line">        RecordMetadata metadata=<span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            metadata = (RecordMetadata) producer.send(record).get();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> metadata;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 异步发送信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">asyncSentMessage</span><span class="params">(String key,String message,String topic)</span></span>&#123;</span><br><span class="line">        ProducerRecord&lt;String,String&gt;record=<span class="keyword">new</span> ProducerRecord(key,message,topic);</span><br><span class="line">        producer.send(record, <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@Param</span> exception 发送返回的异常</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="生产者的配置"><a href="#生产者的配置" class="headerlink" title="生产者的配置"></a>生产者的配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1.acks   acks指定要有多少个分区副本收到消息,生产者才会认为消息写入是成功的.</span><br><span class="line">  acks&#x3D;0  生产者不会等待任何broker服务器的响应.</span><br><span class="line">  acks&#x3D;1  leader节点响应</span><br><span class="line">  acks&#x3D;all 参与复制的所有节点全部收到消息后,生产者才会收到一个来自服务器的成功响应.</span><br><span class="line">2.buffer.memory</span><br><span class="line">  生产者内存缓存区的大小,生产者用它缓冲发送到服务器的消息.</span><br><span class="line">  message ---&gt; buffer ---&gt; 发送出去</span><br><span class="line">  若生产速度大于发送速度,且buffer空间不足,这时候,send()方法要么阻塞,要么抛出异常(max.block.ms参数表示在抛出异常之前可以阻塞一段时间). </span><br><span class="line">3.compression.type</span><br><span class="line">  压缩算法类型 ---&gt; snappy, gzip ,lz4</span><br><span class="line">4.retries  生产者可以重发消息的次数.</span><br><span class="line">  retry.backoff.ms 重试的时间间隔</span><br><span class="line">  时间间隔最好测试以下恢复一个奔溃节点需要多长时间.</span><br><span class="line">5.batch.size  批次可以使用的内存的大小.按照字节数算,并不是指消息个数.</span><br><span class="line">6.linger.ms   生产者在发送批次之前等待更多消息加入批次的时间.</span><br><span class="line">  KafkaProducer会在消息批次填满或者在linger.ms达到上限时把批次发送出去.</span><br><span class="line">7.client.id   标识消息的来源.</span><br><span class="line">8.max.in.flight.requests.per.connection 生产者在收到服务器响应之前可以发送多少个消息.</span><br><span class="line">  设为1可以保证消息是按照发送的顺序写入服务器的,即使发生了重试.</span><br><span class="line">9.timeout.ms,request.timeout.ms和metadata.fetch.timeout.ms</span><br><span class="line">  request.timeout.ms  生产者发送数据等待服务器返回响应的时间.</span><br><span class="line">  metadata.fetch.timeout.ms 生产者获取元数据(比如目标分区首领是谁)时等待服务器返回响应的时间.</span><br><span class="line">  timeout.ms                broker等待同步副本返回消息确认的时间.</span><br><span class="line">10.max.blockms    发送缓冲区满时阻塞的时间,若超过设定,则抛出异常.</span><br><span class="line">11.max.request.size 生产者发送请求的大小</span><br><span class="line">12.receive.buffer.bytes&#x2F;send.buffer.bytes  Tcp socket 接收和发送数据包的缓冲区的大小.</span><br><span class="line">   -1  表示使用操作系统的默认值.</span><br><span class="line">   增大buffer 可以减少tcp 传送报文次数.</span><br></pre></td></tr></table></figure>
<h4 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kafka可以保证同一个分区里的消息写入是有序的.</span><br><span class="line">特殊情况:</span><br><span class="line">参数:retries 不为0 ,max.in.flight.requests.per.connection不为1</span><br><span class="line">场景:  A batch 失败</span><br><span class="line">      B batch 成功</span><br><span class="line">      A batch 重试</span><br><span class="line">max.in.flight.requests.per.connection&#x3D;1 能确保顺序保证,但是在收到响应前不能发送请求会降低吞吐量.</span><br></pre></td></tr></table></figure>
<h3 id="序列化器"><a href="#序列化器" class="headerlink" title="序列化器"></a>序列化器</h3><h4 id="自定义序列化器"><a href="#自定义序列化器" class="headerlink" title="自定义序列化器"></a>自定义序列化器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">java bean 类.</span><br><span class="line">public class Customer &#123;</span><br><span class="line">    private int customerID;</span><br><span class="line">    private String customerName;</span><br><span class="line"></span><br><span class="line">    public Customer(int customerID, String customerName) &#123;</span><br><span class="line">        this.customerID &#x3D; customerID;</span><br><span class="line">        this.customerName &#x3D; customerName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getCustomerID() &#123;</span><br><span class="line">        return customerID;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setCustomerID(int customerID) &#123;</span><br><span class="line">        this.customerID &#x3D; customerID;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getCustomerName() &#123;</span><br><span class="line">        return customerName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setCustomerName(String customerName) &#123;</span><br><span class="line">        this.customerName &#x3D; customerName;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">java 序列化器.</span><br><span class="line">public class CustomSerializer implements Serializer&lt;Customer&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; configs, boolean isKey) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public byte[] serialize(String topic, Customer customer) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (customer &#x3D;&#x3D; null) return null;</span><br><span class="line">            byte[] serializedName;</span><br><span class="line">            int stringSize;</span><br><span class="line">            if (customer.getCustomerName() !&#x3D; null) &#123;</span><br><span class="line">                serializedName &#x3D; customer.getCustomerName().getBytes(&quot;UTF-8&quot;);</span><br><span class="line">                stringSize &#x3D; serializedName.length;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                serializedName &#x3D; new byte[0];</span><br><span class="line">                stringSize &#x3D; 0;</span><br><span class="line">            &#125;</span><br><span class="line">            ByteBuffer buffer &#x3D; ByteBuffer.allocate(4 + 4 + stringSize);</span><br><span class="line">            &#x2F;&#x2F;4(id)+4(length)+length</span><br><span class="line">            buffer.putInt(customer.getCustomerID());</span><br><span class="line">            buffer.putInt(stringSize);</span><br><span class="line">            buffer.put(serializedName);</span><br><span class="line">            return buffer.array();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            throw new SerializationException(&quot;Error when serializing Customer to byte[]&quot; + e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">kafka 发送</span><br><span class="line">  producer.send(new ProducerRecord&lt;String,Customer&gt;(&quot;topic&quot;,&quot;18805199153&quot;,new Customer(&quot;18805199153&quot;,&quot;boss&quot;)));</span><br></pre></td></tr></table></figure>
<h4 id="使用avro序列化"><a href="#使用avro序列化" class="headerlink" title="使用avro序列化"></a>使用avro序列化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.avro是Doug Cutting 创建,目的是提供一种共享数据文件的方式.</span><br><span class="line">2.Customer类对应的schema如下.</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;namespace&quot;:&quot;customerManagement.avro&quot;,</span><br><span class="line">    &quot;type&quot;:&quot;record&quot;,</span><br><span class="line">    &quot;name&quot;:&quot;Customer&quot;,</span><br><span class="line">    &quot;fields&quot;:[</span><br><span class="line">      &#123;&quot;name&quot;:&quot;id&quot;,&quot;type&quot;:&quot;int&quot;&#125;,</span><br><span class="line">      &#123;&quot;name&quot;:&quot;name&quot;,&quot;type&quot;:&quot;string&quot;&#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">3.在kafka中使用avro.</span><br><span class="line">  1.数据类型(例如customer)的schema并不属于kafka.</span><br><span class="line">    schema是放在schema注册表中.存在kafka的消息含有schema标识符,解编码时根据标识符去获取schema.</span><br><span class="line">  2.发送方.</span><br><span class="line">        kafkaProps.put(&quot;key.serializer&quot;,&quot;io.confluent.kafka.serializers.KafkaAvroSerializer&quot;);</span><br><span class="line">        kafkaProps.put(&quot;value.serializer&quot;,&quot;io.confluent.kafka.serializers.KafkaAvroSerializer&quot;);</span><br><span class="line">        kafkaProps.put(&quot;schema.registry.url&quot;,&quot;&quot;);</span><br><span class="line">        producer&#x3D;new KafkaProducer(kafkaProps);</span><br><span class="line">        ProducerRecord&lt;String,Customer&gt;record&#x3D;new ProducerRecord(&quot;topicA&quot;,&quot;18805199153&quot;,new Customer(&quot;18805199153&quot;,&quot;boos&quot;));</span><br><span class="line">        producer.send(record);</span><br></pre></td></tr></table></figure>
<h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1.键有2个用途:</span><br><span class="line">  1.决定消息被写到主题的哪个分区.</span><br><span class="line">  2.作为消息的附加信息.</span><br><span class="line">2.拥有相同键的消息将被写到同一个分区(分区器).</span><br><span class="line">  ps:一个进程从一个主题的分区读取数据,那么具有相同键的所有记录都会被该进程读取(topic的某个分区在同一时刻只能消费者组的一个消费者消费).</span><br><span class="line">3.key为null的消息.</span><br><span class="line">  ProducerRecord&lt;Integer,String&gt;record&#x3D;new ProducerRecord&lt;&gt;(&quot;CustomerCountry&quot;,”Laboratory Equipment&quot;,&quot;USA&quot;);</span><br><span class="line">    创建键为null的消息.</span><br><span class="line">   ProducerRecord&lt;Integer,String&gt;record&#x3D;new ProducerRecord&lt;&gt;(&quot;CustomerCountry&quot;,&quot;USA&quot;);</span><br><span class="line">  如果key为null,并且使用了默认的分区器,那么记录将会被发送到主题内各个可用的分区上(Round Robin).</span><br><span class="line">4.key不为null,并且使用了默认的分区器,kafka会对key进行散列,根据散列值将消息映射到特定的分区上.</span><br></pre></td></tr></table></figure>
<h4 id="实现自定义的分区策略"><a href="#实现自定义的分区策略" class="headerlink" title="实现自定义的分区策略"></a>实现自定义的分区策略</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.根据消息级别可以为一些重要的消息存储到专门的分区上.</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BananaPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span> || !(key <span class="keyword">instanceof</span> String)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> InvalidRecordException(<span class="string">"We expect all messages to have customer name as key"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (key.toString().equals(<span class="string">"Banana"</span>)) &#123;</span><br><span class="line">            <span class="comment">//banana 总是分配到最后一个分区</span></span><br><span class="line">            <span class="keyword">return</span> numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Math.abs(Utils.murmur2(keyBytes) % (numPartitions - <span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.生产者示例.</span><br><span class="line">2.同步和异步2种发送方式.</span><br><span class="line">3.生产者配置参数.</span><br><span class="line">4.Avro序列化器.</span><br><span class="line">5.kafka分区机制.</span><br></pre></td></tr></table></figure>
<h2 id="第四章-Kafka消费者-从kafka读取数据"><a href="#第四章-Kafka消费者-从kafka读取数据" class="headerlink" title="第四章 Kafka消费者-从kafka读取数据"></a>第四章 Kafka消费者-从kafka读取数据</h2><h3 id="KafkaConsumer概念"><a href="#KafkaConsumer概念" class="headerlink" title="KafkaConsumer概念"></a>KafkaConsumer概念</h3><h4 id="消费者和消费者群组"><a href="#消费者和消费者群组" class="headerlink" title="消费者和消费者群组"></a>消费者和消费者群组</h4><p><img src="/2020/02/07/kafka/topic-consumer-group.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">消费者群组产生的原因: 生产者往主题写入消息的速度超过了单个应用程序验证数据的速度,所以需要多个消费者避免消息的堆积.</span><br></pre></td></tr></table></figure>
<h4 id="消费者群组和分区再均衡"><a href="#消费者群组和分区再均衡" class="headerlink" title="消费者群组和分区再均衡"></a>消费者群组和分区再均衡</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.再均衡是指分区所有权从一个消费者转移到另一个消费者.</span><br><span class="line">    再均衡非常重要,为消费者群组带来了高可用性和伸缩性.</span><br><span class="line">2.消费者通过向被指派为群首协调器(coordinator)的broker(不同的群组有不同的协调器)发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系,</span><br><span class="line">  消费者  ---ping---&gt; broker(coordinator)</span><br><span class="line">  1.只要消费者以正常的时间间隔发送心跳,就被认为是活跃的,说明它还在读取分区里的消息.</span><br><span class="line">  2.消费者会在轮询消息(为了获取消息)或者提交偏移量时候发送心跳.</span><br><span class="line">  3.如果消费者过期,群组协调器(coordinator-broker)认为它已经死亡,就会触发一次再均衡.</span><br></pre></td></tr></table></figure>
<h4 id="分配分区的过程"><a href="#分配分区的过程" class="headerlink" title="分配分区的过程"></a>分配分区的过程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    群主(group leader)  &lt;&#x3D;&#x3D;&#x3D;&gt;  群组协调器(coordinator-broker)</span><br><span class="line">1.消费者加入群组时候,它会向群组协调器(coordinator-broker)发送一个JoinGroup请求.</span><br><span class="line">2.第一个加入群组的消费者将会成为&quot;群主&quot;.</span><br><span class="line">3.群主从协调器那里获得群组的成员列表(列表包含了所有最近发送过心跳的消费者,它们被认为是活跃的),并负责给每一个消费者分配分区.</span><br><span class="line">4.群主使用一个实现了PartitionAssignor接口的类决定哪些分区应该被分配给哪个消费者.</span><br><span class="line">5.分配完成后,群主把分配情况列表发给群组协调器,协调器再把这些消息发送给所有的消费者.</span><br><span class="line">6.每个消费者只能看到自己的分配信息,只有群主知道群组里所有消费者的分配信息.</span><br><span class="line">   这个过程在再平衡时重复发生.</span><br></pre></td></tr></table></figure>
<h3 id="创建kafka消费者"><a href="#创建kafka消费者" class="headerlink" title="创建kafka消费者"></a>创建kafka消费者</h3><h4 id="KafkaConsumer对象的创建"><a href="#KafkaConsumer对象的创建" class="headerlink" title="KafkaConsumer对象的创建"></a>KafkaConsumer对象的创建</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Properties props=<span class="keyword">new</span> Properties();</span><br><span class="line">props.put(<span class="string">"bootstrap.servers"</span>,<span class="string">"192.168.78.129:9092"</span>);</span><br><span class="line"><span class="comment">//群组名称</span></span><br><span class="line">props.put(<span class="string">"group.id"</span>,<span class="string">"CountryCounter"</span>);</span><br><span class="line">props.put(<span class="string">"key.deserializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">props.put(<span class="string">"value.deserializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">KafkaConsumer&lt;String,String&gt;consumer=<span class="keyword">new</span> KafkaConsumer&lt;String,String&gt;(props);</span><br></pre></td></tr></table></figure>
<h3 id="订阅主题"><a href="#订阅主题" class="headerlink" title="订阅主题"></a>订阅主题</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//传入一个topic 列表</span></span><br><span class="line">consumer.subscribe(Collections.singletonList(<span class="string">"customerCountries"</span>));</span><br><span class="line"><span class="comment">//传入正则表达式</span></span><br><span class="line">consumer.subscribe(<span class="string">"test.*"</span>);</span><br></pre></td></tr></table></figure>
<h3 id="轮询"><a href="#轮询" class="headerlink" title="轮询"></a>轮询</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">一旦消费者订阅了主题,轮询就会处理所有的细节,包括群组协调,分区再均衡,发送心跳和获取数据.</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    <span class="comment">//阻塞100毫秒</span></span><br><span class="line">    ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">      log.debug(<span class="string">"topic = %s,partition = %s,offset=%d,customer = %s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">      <span class="keyword">int</span> updatedCount=<span class="number">1</span>;</span><br><span class="line">      <span class="keyword">if</span>(custCountryMap.containsValue(record.value()))&#123;</span><br><span class="line">        updatedCount=custCountryMap.get(record.value())+<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      custCountryMap.put(record.value(),updatedCount);</span><br><span class="line">      JSONObject json=<span class="keyword">new</span> JSONObject(custCountryMap);</span><br><span class="line">      System.out.println(json.toString());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">  consumer.close();</span><br><span class="line">&#125;</span><br><span class="line">轮询不仅仅是获取数据,在第一次调用消费者的poll方法时候,</span><br><span class="line">  <span class="number">1</span>.首先查找GroupCoordinator(broker).</span><br><span class="line">  <span class="number">2</span>.加入群组.</span><br><span class="line">  <span class="number">3</span>.接受群主(consumer)分配的分区.</span><br><span class="line">  ps:若发生再均衡,整个过程也是在轮询期间poll方法进行的.</span><br></pre></td></tr></table></figure>
<h4 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.在同一个群组里,一个线程运行多个消费者,多个线程运行一个消费者都是禁止的.</span><br><span class="line">2.一个线程对应一个消费者(ExecutorService). I&#x2F;O模式.</span><br></pre></td></tr></table></figure>
<h3 id="消费者的配置"><a href="#消费者的配置" class="headerlink" title="消费者的配置"></a>消费者的配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">1.fetch.min.bytes         该属性指定了消费者从服务器获取记录的最小字节数.(在低峰时候可以设置大一点,减少来回传输的次数)</span><br><span class="line">2.fetch.max.wait.ms       指定broker的等待时间,默认500ms.如果没有足够的数据流入kafka,消费者获取最小数据量的要求就得不到满足,最终导致500ms的延迟.</span><br><span class="line">                          即: 若 fetch.min.bytes设置为1MB,当kafka不能返回大于1mb的数据时候,会阻塞500ms.</span><br><span class="line">3.max.partition.fetch.bytes 服务器从每个分区里返回给消费者的最大字节数.max.partition.fetch.bytes必须比borker能够接收的最大消息的字节数(max.message.size)大,否则消费者可能无法读取这些消息.</span><br><span class="line">4.session.timeout.ms      默认是3秒,如果消费者没有在3秒内发送心跳给群组协调器,就被认为已经死亡.协调器会触发再均衡,把它的分区分配给群组里的其它消费者.</span><br><span class="line">                          heartbeat.interval.ms是指poll方法向协调器发送心跳的频率.</span><br><span class="line">                          垃圾收集(STW)可能导致非预期的再均衡,可以将session.timeout.ms值调整的大一些.   </span><br><span class="line">5.auto.offset.reset       当消费者在读取一个没有偏移量或者偏移量无效的情况下(因消费者长时间失效,包含偏移量的记录已经过时并删除)该如何处理.</span><br><span class="line">                          默认值是latest,即偏移量无效的情况下,消费者将从最新的记录(在消费者启动之后生成的记录)开始读取数据.</span><br><span class="line">                          可选值earlies,当偏移量无效的情况下,消费者将从起始位置读取分区的记录.</span><br><span class="line">6.enable.auto.commit      该属性指定了消费者是否自动提交偏移量,默认是true.为了尽量避免出现重复数据和数据丢失,可以将它设为false.</span><br><span class="line">                          auto.commit.interval.ms 控制自动提交的频率.</span><br><span class="line">7.partition.assignment.strategy   分区分配给群组里消费者的策略. </span><br><span class="line">                          kafka默认的2个分配策略.PartitionAssignor会根据给定的消费者和主题,决定哪些分区应该分配给哪个消费者.</span><br><span class="line">                          Range策略会把主题的若干个连续的分区分配给消费者.靠前的消费者总是比靠后的消费者获得更多的分区.</span><br><span class="line">                          RoundRobin策略把主题的所有分区逐个分配给消费者.</span><br><span class="line">                          例如有2个主题,每个主题有三个分区.2个消费者属于一个群组,同时订阅2个主题.</span><br><span class="line">                          TopicA ---&gt;P0,P1,P2</span><br><span class="line">                          TopicB ---&gt;P0,P1,P2</span><br><span class="line">                          Range策略:  C1: AP0,AP1,BP0,BP1 C2:AP2,BP2.</span><br><span class="line">                          RoundRobin策略: C1:AP0,AP2,BP1  C2:AP1,BP0,BP2.</span><br><span class="line">8.client.id               broker用来标识从客户端发送过来的信息.</span><br><span class="line">9.max.poll.records        call方法返回的记录数量.</span><br><span class="line">10.receive.buffer.bytes和send.buffer.bytes </span><br><span class="line">                         socket读写数据的TCP缓冲区的大小,若低带宽和高延迟,可以适量增大缓冲区大小,减少网络传输次数.</span><br></pre></td></tr></table></figure>
<h3 id="提交和偏移量"><a href="#提交和偏移量" class="headerlink" title="提交和偏移量"></a>提交和偏移量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.kafka不像其它的JMS队列那样需要得到消费者的确认,消费者可以通过kafka来追踪消息在分区里的位置(偏移量).</span><br><span class="line">2.更新分区当前位置的操作叫做提交.</span><br><span class="line">3.消费者如何提交偏移量?</span><br><span class="line">  消费者向_consumer_offset这个特殊主题发送消息,消息包含每个分区的偏移量.</span><br><span class="line">  如果消费者一直处于运行状态,那么偏移量就没有什么用处.</span><br><span class="line">  当消费者奔溃或者有新的消费者加入时候,就会触发再均衡.</span><br><span class="line">  再均衡过后,为了继续之前的工作,消费者需要读取每个分区的最后一次提交的偏移量,然后从偏移量指定的地方继续处理.</span><br><span class="line">  如果上一次提交的偏移量小于客户端处理最后一个消息的偏移量.那么位于两个偏移量之间的消息会被重复处理.</span><br><span class="line">  如果上一次提交的偏移量大于客户端处理最后一个消息的偏移量.那么位于两个偏移量之间的消息会被抛弃.</span><br></pre></td></tr></table></figure>
<h4 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.enable.auto.commit ---&gt; true 每隔auto.commit.interval.ms,消费者会自动将poll方法接收到的最大偏移量提交上去.</span><br><span class="line">问题: 若auto.commit.interval.ms为10s,消费者在提交后的第4秒发生了再均衡.</span><br><span class="line">      再均衡后消费者从上一次提交偏移量位置读取消息,这时候偏移量已经晚了4秒,会导致4秒的消息重复处理.</span><br></pre></td></tr></table></figure>
<h4 id="手动提交当前偏移量"><a href="#手动提交当前偏移量" class="headerlink" title="手动提交当前偏移量"></a>手动提交当前偏移量</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">kafkaProps.put(<span class="string">"enable.auto.commit"</span>,<span class="keyword">false</span>);</span><br><span class="line">.....</span><br><span class="line">同步提交偏移量.</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">    System.out.printf(<span class="string">"topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    consumer.commitSync();<span class="comment">//同步的方式提交当前批次最新的偏移量</span></span><br><span class="line">  &#125;<span class="keyword">catch</span>(CommitFailedExecption e)&#123;</span><br><span class="line">    log.error(<span class="string">"commit failed"</span>,e); <span class="comment">//提交失败,记录异常.</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">异步提交偏移量.</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">    System.out.println(<span class="string">"topic=%s,partition=%s,offset=%s,customer=%s,country=%s"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">  &#125;</span><br><span class="line">  consumer.commitAsync();</span><br><span class="line">&#125;</span><br><span class="line">问题: </span><br><span class="line">  异步返回:</span><br><span class="line">    A消费一批消息,异步提交偏移量<span class="number">2000</span>,这时网络波动,卡了</span><br><span class="line">    A消费一批消息,异步提交偏移量<span class="number">3000</span>,成功.</span><br><span class="line">    A提交<span class="number">2000</span>成功.</span><br><span class="line">    可能会导致在再均衡时候消息重复消费.</span><br><span class="line">异步提交使用回调函数.</span><br><span class="line">问题的解决</span><br><span class="line">  可以在jvm堆中维护每次提交的偏移量,若回调时发现堆中的本地偏移量没有比返回的新(网络正常),则出现异常可以重试,否则出现异常则忽略.</span><br><span class="line">Map&lt;String,Long&gt;offsetMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">    System.out.printf(<span class="string">"topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  consumer.commitAsync(<span class="keyword">new</span> OffsetCommitCallback()&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition,OffsetAndMetadata&gt;offsets,Exception e)</span></span>&#123;</span><br><span class="line">        offsets.forEach((tP,oAM)-&gt;&#123;</span><br><span class="line">          Long offset=offsetMap.putIfAbsent(tp.topic()+tp.partition(),oAM.offset());</span><br><span class="line">          <span class="keyword">if</span>(e!=<span class="keyword">null</span>)&#123;</span><br><span class="line">          <span class="comment">//出现异常</span></span><br><span class="line">          <span class="keyword">if</span>(offset!=<span class="keyword">null</span>&amp;&amp;offset&lt;(oAM.offset()))&#123;</span><br><span class="line">            <span class="comment">//重试</span></span><br><span class="line">          &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//说明消息已经被处理了</span></span><br><span class="line">            offsetMap.put(tp.topic()+tp.partition(),offset);</span><br><span class="line">          &#125;</span><br><span class="line">         &#125;</span><br><span class="line">        );</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125; </span><br><span class="line">同步和异步组合提交</span><br><span class="line">为了使得消费者关闭(正常或异常退出)之前也能提交,需要使用同步的api提交下偏移量.</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">      log.info(<span class="string">"topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitAsync();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">  log.error(<span class="string">"Unexpected error"</span>,e);</span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="comment">//关闭前,同步的提交下偏移量</span></span><br><span class="line">    consumer.commitSync();</span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">提交batch中特定偏移量,默认的commitSync,commitAsync只能提交batch的最后一个消息的偏移量.</span><br><span class="line">ps: 消费者可以多主题,多分区消费.</span><br><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition,OffsetAndMetadata&gt;currentOffsets=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">int</span> count =<span class="number">0</span>;<span class="comment">//消息个数</span></span><br><span class="line">.....</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,String&gt; records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">    log.info(<span class="string">"topic=%s,partition=%s,offset=%s,customer=%s,country=%s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">    currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(),record.partition()),<span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>,<span class="string">"no metadata));</span></span><br><span class="line"><span class="string">    if(count%1000==0)</span></span><br><span class="line"><span class="string">      consumer.commitAsync(currentOffsets,null);</span></span><br><span class="line"><span class="string">    count++;   </span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="再均衡监听器"><a href="#再均衡监听器" class="headerlink" title="再均衡监听器"></a>再均衡监听器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">消费者群主  消费者群组协调器</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  consumer.subscribe(topics,<span class="keyword">new</span> ConsumerRebalanceListener()&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 该方法会在重新分配分区之后和消费者开始读取消息之前被调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt;partitions)</span></span>&#123;</span><br><span class="line">      log.info(<span class="string">"新分配到的分区&#123;&#125;"</span>,partitions);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 该方法会在再均衡开始之前和消费者停止读取消息之后被调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt;partitions)</span></span>&#123;</span><br><span class="line">      log.info(<span class="string">"再均衡即将发生,目前的分区%s"</span>,partitions);</span><br><span class="line">      <span class="comment">//!!!! 这里可以将已经处理的偏移量提交,防止重复处理消息等</span></span><br><span class="line">      consumer.commitSync(currentOffsets);</span><br><span class="line">      </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord &lt;String,String&gt;record:records)&#123;</span><br><span class="line">      log.info(<span class="string">"topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n"</span>,record.topic(),record.partition(),record.offset(),record.key(),record.value());</span><br><span class="line">      currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(),record.partition()),<span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>,<span class="string">"no metadata"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitAsync(currentOffsets,<span class="keyword">null</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;<span class="keyword">catch</span>(WakeupException e)&#123;</span><br><span class="line">  </span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">  log.error(<span class="string">"Unexpected error"</span>,e);</span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    consumer.commitSync(currentOffsets);</span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="从特定偏移量处开始处理记录"><a href="#从特定偏移量处开始处理记录" class="headerlink" title="从特定偏移量处开始处理记录"></a>从特定偏移量处开始处理记录</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.从分区起始位置开始读取消息.</span><br><span class="line">consumer.seekToBeginning(Collection&lt;TopicPartition&gt;tp);</span><br><span class="line"><span class="number">2</span>.从分区末尾开始读取消息.</span><br><span class="line">consumer.seekToEnd(Collection&lt;TopicPartition&gt;tp);</span><br><span class="line">场景: 应用程序从Kafka读取事件(可能是网站的用户点击事件流),对它们进行处理(可能是使用自动程序清理点击操作并添加会话信息).</span><br><span class="line">      然后把结果保存到数据库,NoSql存储引擎或Hadoop中.</span><br><span class="line">   <span class="number">1</span>.不想丢失任何数据,不想重复保存---&gt;每处理一个消息,就提交一次.</span><br><span class="line">   <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">     ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">100</span>)；</span><br><span class="line">     <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">       currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(),record.partition()),<span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>));</span><br><span class="line">       processRecord(record);</span><br><span class="line">       storeRecord(record);</span><br><span class="line">       consumer.commitAsync(currentOffsets);</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="number">2</span>.上诉做法存在问题,即存储record(storeRecord)和存储offset(commitAsync)不是原子性的.</span><br><span class="line">     解决方式,在batch都处理完后将offset存储到数据库中,在再均衡后,从数据库中读取partition的offset.</span><br><span class="line">     <span class="class"><span class="keyword">class</span> <span class="title">SaveOffsetsOnRebalance</span> <span class="keyword">implements</span> <span class="title">ConsumerRebalanceListener</span></span>&#123;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt;partitions)</span></span>&#123;</span><br><span class="line">         commitDBTransaction(); <span class="comment">//提交数据库事务</span></span><br><span class="line">       &#125;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt;partitions)</span></span>&#123;</span><br><span class="line">         <span class="keyword">for</span>(TopicPartition partition:partitions)&#123;</span><br><span class="line">           <span class="comment">//再均衡时从数据库中获取每个分区的偏移量</span></span><br><span class="line">           consumer.seek(partition,getOffsetFromDB(partition));</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     consumer.subscribe(topics,<span class="keyword">new</span> SaveOffsetOnRebalance(consumer));</span><br><span class="line">     consumer.poll(<span class="number">0</span>);<span class="comment">//消费者加入消费者群组,获取分配到的分区.</span></span><br><span class="line">     <span class="keyword">for</span>(TopicPartition partition:consumer.assignment())&#123;</span><br><span class="line">       consumer.seek(partition,getOffsetFromDB(partition));<span class="comment">//定位每个分区的偏移量</span></span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">       ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">1000</span>);</span><br><span class="line">       <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">         processRecord(record);</span><br><span class="line">         storeRecord(record);</span><br><span class="line">         storeOffsetInDB(record.topic(),record.partition(),record.offset());</span><br><span class="line">       &#125;</span><br><span class="line">       commitDBTransaction(); <span class="comment">//提交事务</span></span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<h3 id="如何退出"><a href="#如何退出" class="headerlink" title="如何退出"></a>如何退出</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.消费者如何优雅的退出?</span><br><span class="line">  java线程是主动式线程.其它线程通过thread.interrupt()方法可以为thread设置中断位.thread可以通过thread.isInterrupted()方法检测并抛出InterruptedException</span><br><span class="line">  <span class="number">1</span>.consumer可以通过consumer.wakeup方法退出循环.</span><br><span class="line">  <span class="number">2</span>.consumer.wakeup方法会在下一轮poll时候抛出WakeupException.</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ShutdownHook运行在单独的线程中,在客户端被关闭时候调用</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">      System.out.println(<span class="string">"Starting exit..."</span>);</span><br><span class="line">      <span class="comment">//在客户端关闭时候去中断循环</span></span><br><span class="line">      consumer.wakeup();</span><br><span class="line">      <span class="keyword">try</span>&#123;</span><br><span class="line">        mainThread.join();</span><br><span class="line">      &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line">......</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="comment">//循环,直到按下CTRL+C键,关闭的钩子会在退出时进行清理</span></span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">1000</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">      log.info(<span class="string">"offset=%d,key=%s,value=%s\n"</span>,record.offset(),record.key(),record.value());</span><br><span class="line">      currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(),record.partition()),<span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>,<span class="string">"no metadata"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(TopicPartiton tp :consumer.assignment())&#123;</span><br><span class="line">      log.info(<span class="string">"Committing offset at position:"</span>+consumer.position(tp));</span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;<span class="keyword">catch</span>(WakeupException e)&#123;</span><br><span class="line">  consumer.commitSync(currentOffsets);</span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">  consumer.close();</span><br><span class="line">  log.info(<span class="string">"Closed consumer and we are done"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="反序列化器"><a href="#反序列化器" class="headerlink" title="反序列化器"></a>反序列化器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.生产者需要用序列化器把对象转换成字节数组发送给kafka.消费者需要调用反序列化器把从kafka接收到的字节数组转换成java对象.</span><br></pre></td></tr></table></figure>
<h4 id="自定义反序列化器"><a href="#自定义反序列化器" class="headerlink" title="自定义反序列化器"></a>自定义反序列化器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">bean类</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> customerId;</span><br><span class="line">  <span class="keyword">private</span> String customerName;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(<span class="keyword">int</span> ID,String name)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.customerId=ID;</span><br><span class="line">    <span class="keyword">this</span>.name=name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">反序列化器类</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerDeserializer</span> <span class="keyword">implements</span> <span class="title">Deserializer</span>&lt;<span class="title">Customer</span>&gt;</span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs,<span class="keyword">boolean</span> isKey)</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Customer <span class="title">deserialize</span><span class="params">(String topic,<span class="keyword">byte</span>[]data)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">int</span> nameSize;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(data==<span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span>(data.length&lt;<span class="number">0</span>) <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Size of data received by IntegerDeserizlizer is shorter than expected"</span>);</span><br><span class="line">      ByteBUffer buffer=ByteBuffer.warp(data);</span><br><span class="line">      id=buffer.getInt();</span><br><span class="line">      nameSize=buffer.getInt();</span><br><span class="line">      <span class="keyword">byte</span>[]nameBytes=<span class="keyword">new</span> bute[nameSize];</span><br><span class="line">      buffer.get(nameBytes);</span><br><span class="line">      name =<span class="keyword">new</span> String(nameBytes,<span class="string">"UTF-8"</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> Customer(id,name);</span><br><span class="line">    &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Error when serializing Customer to byte[]"</span>+e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">消费者配置</span><br><span class="line">Properties props=<span class="keyword">new</span> Properties();</span><br><span class="line">props.put(<span class="string">"bootstrap.servers"</span>,<span class="string">"broker1:9002"</span>);</span><br><span class="line">props.put(<span class="string">"group.id"</span>,<span class="string">"CountryCounter"</span>);</span><br><span class="line">props.put(<span class="string">"key.deserializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">props.put(<span class="string">"value.deserializer"</span>,<span class="string">"org.apache.kafka.common.serialization.CustomerDeserializer"</span>);</span><br><span class="line">KafkaConsumer&lt;String,Customer&gt; consumer=<span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Collections.singleList(<span class="string">"customerCountries"</span>));</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,Customer&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,Customer&gt;record:records)&#123;</span><br><span class="line">    System.out.println(<span class="string">"current customer id: "</span>+record.value().getId()+<span class="string">" and current Customer name:"</span>+record.value().getName());</span><br><span class="line">  &#125;</span><br><span class="line">  consumer.commitAsync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="avro-反序列化"><a href="#avro-反序列化" class="headerlink" title="avro 反序列化"></a>avro 反序列化</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Properties props=<span class="keyword">new</span> Properties();</span><br><span class="line">props.put(<span class="string">"bootstrap.servers"</span>,<span class="string">"broker1:9002"</span>);</span><br><span class="line">props.put(<span class="string">"group.id"</span>,<span class="string">"CountryCounter"</span>);</span><br><span class="line">props.put(<span class="string">"key.deserializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"><span class="comment">//设置avro反序列化器</span></span><br><span class="line">props.put(<span class="string">"value.deserializer"</span>,<span class="string">"io.confluent.kafka.serializers.KafkaAvroDeserializer"</span>);</span><br><span class="line"><span class="comment">//设置schemaUrl</span></span><br><span class="line">props.put(<span class="string">"schema.registry.url"</span>,schemaUrl);</span><br><span class="line">KafkaConsumer&lt;String,Customer&gt; consumer=<span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Collections.singleList(<span class="string">"customerCountries"</span>));</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">  ConsumerRecords&lt;String,Customer&gt;records=consumer.poll(<span class="number">100</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord&lt;String,Customer&gt;record:records)&#123;</span><br><span class="line">    System.out.println(<span class="string">"current customer id: "</span>+record.value().getId()+<span class="string">" and current Customer name:"</span>+record.value().getName());</span><br><span class="line">  &#125;</span><br><span class="line">  consumer.commitAsync();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="独立的消费者-如何使用没有群组的消费者"><a href="#独立的消费者-如何使用没有群组的消费者" class="headerlink" title="独立的消费者-如何使用没有群组的消费者"></a>独立的消费者-如何使用没有群组的消费者</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.场景:   </span><br><span class="line">  当处理简单的东西,比如你只从一个消费者或从一个主题的所有分区或者特定的分区读取数据,这时候不需要群组和再均衡了,</span><br><span class="line">  只需要把主题或者分区分配给消费者,然后再开始读取消息并提交偏移量.</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 我觉得不设置group.id属性可以</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">List&lt;PartitionInfo&gt;partitionInfos=<span class="keyword">null</span>;</span><br><span class="line">partitionInfos=consumer.partitionsFor(<span class="string">"topic"</span>);</span><br><span class="line"><span class="keyword">if</span>(partitionInfos!=<span class="keyword">null</span>)&#123; </span><br><span class="line">  <span class="keyword">for</span>(PartitionInfo partition:partitionInfos)&#123;</span><br><span class="line">    partitions.add(<span class="keyword">new</span> TopicPartition(partition.topic(),partition.partition()));</span><br><span class="line">  &#125;</span><br><span class="line">  consumer.assign(partitions);</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">    ConsumerRecords&lt;String,String&gt;records=consumer.poll(<span class="number">1000</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord&lt;String,String&gt;record:records)&#123;</span><br><span class="line">      log.info(<span class="string">"topic = %s,partition=%s,offset=%d,customer=%s,country=%s\n"</span>,record,topic(),record.partition(),record.offset(),</span><br><span class="line">      record.key(),record.value()</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="旧版的消费者API"><a href="#旧版的消费者API" class="headerlink" title="旧版的消费者API"></a>旧版的消费者API</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">旧版的消费者API ZooKeeperConsumerConnector是使用ZooKeeper来管理消费者群组,并不具备提交偏移量和再均衡的可操控性.</span><br><span class="line">新版的消费者API Consumer 是通过Kafka的_consumer_offset保存消费者的偏移量,可以提交偏移量和再均衡.</span><br></pre></td></tr></table></figure>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.kafka消费者群组概念.  原因: 生产者生产过快. kafka消费者群组支持多个消费者从topic上读取消息.</span><br><span class="line">2.消费者订阅主题并持续读取消息.</span><br><span class="line">3.消费者参数配置.</span><br><span class="line">3.偏移量以及偏移量提交和管理.</span><br><span class="line">4.再均衡(Listener).</span><br><span class="line">5.关闭消费者.</span><br><span class="line">6.反序列化器.</span><br></pre></td></tr></table></figure>
    </div>

    
    
    
		<div>
			
				<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

			
		</div>

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/java/" rel="tag"># java</a>
              <a href="/tags/kafka/" rel="tag"># kafka</a>
              <a href="/tags/messaging/" rel="tag"># messaging</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/06/Spike-system/" rel="prev" title="Spike-system">
      <i class="fa fa-chevron-left"></i> Spike-system
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/10/nosql/" rel="next" title="nosql">
      nosql <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka基本概念"><span class="nav-number">1.</span> <span class="nav-text">Kafka基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#发布和订阅系统"><span class="nav-number">1.1.</span> <span class="nav-text">发布和订阅系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka简介"><span class="nav-number">1.2.</span> <span class="nav-text">kafka简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#消息和批次"><span class="nav-number">1.2.1.</span> <span class="nav-text">消息和批次</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模式-schema"><span class="nav-number">1.2.2.</span> <span class="nav-text">模式-schema</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#主题和分区"><span class="nav-number">1.2.3.</span> <span class="nav-text">主题和分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生产者和消费者"><span class="nav-number">1.2.4.</span> <span class="nav-text">生产者和消费者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#broker和集群"><span class="nav-number">1.2.5.</span> <span class="nav-text">broker和集群</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么选择kafka"><span class="nav-number">1.3.</span> <span class="nav-text">为什么选择kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#多生产者"><span class="nav-number">1.3.1.</span> <span class="nav-text">多生产者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多消费者"><span class="nav-number">1.3.2.</span> <span class="nav-text">多消费者</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于磁盘的数据存储-非实时处理和消息不丢失"><span class="nav-number">1.3.3.</span> <span class="nav-text">基于磁盘的数据存储-非实时处理和消息不丢失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#伸缩性"><span class="nav-number">1.3.4.</span> <span class="nav-text">伸缩性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据生态系统"><span class="nav-number">1.4.</span> <span class="nav-text">数据生态系统</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kafka使用场景"><span class="nav-number">1.4.1.</span> <span class="nav-text">kafka使用场景</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二章-kafka的安装"><span class="nav-number">2.</span> <span class="nav-text">第二章  kafka的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Java"><span class="nav-number">2.1.</span> <span class="nav-text">安装Java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装zookeeper"><span class="nav-number">2.2.</span> <span class="nav-text">安装zookeeper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装kafka"><span class="nav-number">2.3.</span> <span class="nav-text">安装kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#broker配置"><span class="nav-number">2.4.</span> <span class="nav-text">broker配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#常规配置"><span class="nav-number">2.4.1.</span> <span class="nav-text">常规配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#topic的默认配置"><span class="nav-number">2.4.2.</span> <span class="nav-text">topic的默认配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#操作系统调优"><span class="nav-number">2.5.</span> <span class="nav-text">操作系统调优</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#虚拟内存"><span class="nav-number">2.5.1.</span> <span class="nav-text">虚拟内存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#磁盘"><span class="nav-number">2.5.2.</span> <span class="nav-text">磁盘</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#网络"><span class="nav-number">2.5.3.</span> <span class="nav-text">网络</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生产环境的注意事项"><span class="nav-number">2.6.</span> <span class="nav-text">生产环境的注意事项</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#垃圾回收选项"><span class="nav-number">2.6.1.</span> <span class="nav-text">垃圾回收选项</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三章-kafka生产者"><span class="nav-number">3.</span> <span class="nav-text">第三章  kafka生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#生产者概览"><span class="nav-number">3.1.</span> <span class="nav-text">生产者概览</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kafka生产者"><span class="nav-number">3.2.</span> <span class="nav-text">创建kafka生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kafka生产者的3个必须的属性"><span class="nav-number">3.2.1.</span> <span class="nav-text">kafka生产者的3个必须的属性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kafka生产者发送消息的三种方式"><span class="nav-number">3.2.2.</span> <span class="nav-text">kafka生产者发送消息的三种方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#发送消息到kafka"><span class="nav-number">3.2.3.</span> <span class="nav-text">发送消息到kafka</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生产者的配置"><span class="nav-number">3.3.</span> <span class="nav-text">生产者的配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#顺序保证"><span class="nav-number">3.3.1.</span> <span class="nav-text">顺序保证</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#序列化器"><span class="nav-number">3.4.</span> <span class="nav-text">序列化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义序列化器"><span class="nav-number">3.4.1.</span> <span class="nav-text">自定义序列化器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用avro序列化"><span class="nav-number">3.4.2.</span> <span class="nav-text">使用avro序列化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分区"><span class="nav-number">3.5.</span> <span class="nav-text">分区</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#实现自定义的分区策略"><span class="nav-number">3.5.1.</span> <span class="nav-text">实现自定义的分区策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">3.6.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第四章-Kafka消费者-从kafka读取数据"><span class="nav-number">4.</span> <span class="nav-text">第四章 Kafka消费者-从kafka读取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaConsumer概念"><span class="nav-number">4.1.</span> <span class="nav-text">KafkaConsumer概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者和消费者群组"><span class="nav-number">4.1.1.</span> <span class="nav-text">消费者和消费者群组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者群组和分区再均衡"><span class="nav-number">4.1.2.</span> <span class="nav-text">消费者群组和分区再均衡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分配分区的过程"><span class="nav-number">4.1.3.</span> <span class="nav-text">分配分区的过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kafka消费者"><span class="nav-number">4.2.</span> <span class="nav-text">创建kafka消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#KafkaConsumer对象的创建"><span class="nav-number">4.2.1.</span> <span class="nav-text">KafkaConsumer对象的创建</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#订阅主题"><span class="nav-number">4.3.</span> <span class="nav-text">订阅主题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#轮询"><span class="nav-number">4.4.</span> <span class="nav-text">轮询</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#线程安全"><span class="nav-number">4.4.1.</span> <span class="nav-text">线程安全</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费者的配置"><span class="nav-number">4.5.</span> <span class="nav-text">消费者的配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#提交和偏移量"><span class="nav-number">4.6.</span> <span class="nav-text">提交和偏移量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自动提交"><span class="nav-number">4.6.1.</span> <span class="nav-text">自动提交</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#手动提交当前偏移量"><span class="nav-number">4.6.2.</span> <span class="nav-text">手动提交当前偏移量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#再均衡监听器"><span class="nav-number">4.7.</span> <span class="nav-text">再均衡监听器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从特定偏移量处开始处理记录"><span class="nav-number">4.8.</span> <span class="nav-text">从特定偏移量处开始处理记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何退出"><span class="nav-number">4.9.</span> <span class="nav-text">如何退出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#反序列化器"><span class="nav-number">4.10.</span> <span class="nav-text">反序列化器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#自定义反序列化器"><span class="nav-number">4.10.1.</span> <span class="nav-text">自定义反序列化器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#avro-反序列化"><span class="nav-number">4.10.2.</span> <span class="nav-text">avro 反序列化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#独立的消费者-如何使用没有群组的消费者"><span class="nav-number">4.11.</span> <span class="nav-text">独立的消费者-如何使用没有群组的消费者</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#旧版的消费者API"><span class="nav-number">4.12.</span> <span class="nav-text">旧版的消费者API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结-1"><span class="nav-number">4.13.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="vicyor"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">vicyor</p>
  <div class="site-description" itemprop="description">大路且慢慢,咱一步一步走完.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/vicyor" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vicyor" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2457569580@qq.com" title="E-Mail → mailto:2457569580@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">vicyor</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">888k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">13:27</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.6.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = visitors.getAttribute('id').trim();
      var title = visitors.getAttribute('data-flag-title').trim();

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.log('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.log('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return element.getAttribute('id').trim();
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=m9GqFbk5NEr9mLiLAXCyheul-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'm9GqFbk5NEr9mLiLAXCyheul-gzGzoHsz',
            'X-LC-Key': 'g7WSuE6aDmunoX4rgyBN7SJa',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.getScript('//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'qQhr9rNGJh6YalJA0mfaaurx-gzGzoHsz',
    appKey: 'kJy8NJeOTMPnxQ3zLihOcnw3',
    placeholder: "请留下您的宝贵评论",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

	
		 <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
		 <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
		 <script type="text/javascript" src="/js/src/fireworks.js"></script>
	
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body>
</html>
