<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://vicyor.gitee.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="kafka -&gt; 开源的消息引擎系统">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka">
<meta property="og:url" content="http://vicyor.gitee.io/2020/02/07/kafka/index.html">
<meta property="og:site_name" content="Vicyor">
<meta property="og:description" content="kafka -&gt; 开源的消息引擎系统">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/consumer-multi-thread.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/kafka-replica.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/kafka-reactor.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/kafka-reactor-detail.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/join-group.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/sync-group.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/reblance-new-consumer.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/reblance-consumer-leave.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/reblance-consumer-dead.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/reblance-offset.commit.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/kafka-zookeeper.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/controller-data.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/controller-failover.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/hw.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/hw-broker-1.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/hw-broker-2.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/hw-message-miss.png">
<meta property="og:image" content="http://vicyor.gitee.io/2020/02/07/kafka/hw-message-wrong.png">
<meta property="article:published_time" content="2020-02-07T01:50:25.000Z">
<meta property="article:modified_time" content="2020-10-29T00:54:50.598Z">
<meta property="article:author" content="vicyor">
<meta property="article:tag" content="java">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="messaging">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://vicyor.gitee.io/2020/02/07/kafka/consumer-multi-thread.png">

<link rel="canonical" href="http://vicyor.gitee.io/2020/02/07/kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>kafka | Vicyor</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Vicyor</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">49</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">55</span></a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://vicyor.gitee.io/2020/02/07/kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.png">
      <meta itemprop="name" content="vicyor">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vicyor">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-07 09:50:25" itemprop="dateCreated datePublished" datetime="2020-02-07T09:50:25+08:00">2020-02-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-10-29 08:54:50" itemprop="dateModified" datetime="2020-10-29T08:54:50+08:00">2020-10-29</time>
              </span>

          
            <span id="/2020/02/07/kafka/" class="post-meta-item leancloud_visitors" data-flag-title="kafka" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2020/02/07/kafka/#comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/02/07/kafka/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>31k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>kafka -&gt; 开源的消息引擎系统</p>
<a id="more"></a>
<h2 id="kafka入门"><a href="#kafka入门" class="headerlink" title="kafka入门"></a>kafka入门</h2><h3 id="消息引擎系统"><a href="#消息引擎系统" class="headerlink" title="消息引擎系统"></a>消息引擎系统</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.消息传输两种模型.</span><br><span class="line">  1.点对点.</span><br><span class="line">  2.发布&#x2F;订阅模型.</span><br><span class="line">2.JMS -&gt; Java Message Service,Java对消息引擎提供的一种规范接口.</span><br><span class="line">  tips: 支持jms规范的消息队列,ActiveMQ,RabbitMQ,IBM,WebSphere MQ,Apache Kafka.</span><br><span class="line">3.削峰填谷.  -&gt;  缓冲上下游瞬时突发流量.</span><br><span class="line">  tips: 链路的下游服务处理速度一般都比较慢,当上游产生大量流量时候,下游系统会被压垮.</span><br><span class="line">4.异步解耦.</span><br></pre></td></tr></table></figure>
<h3 id="kafka术语"><a href="#kafka术语" class="headerlink" title="kafka术语"></a>kafka术语</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1.主题(topic)  -  发布订阅的对象.</span><br><span class="line">2.生产者(producer)  -  向主题发消息.</span><br><span class="line">3.消费者(consumer)  -  订阅主题消息.</span><br><span class="line">  消费者组(Consumer Group)  -  实现P2P模型.一个group &lt;&#x3D;&gt; 1个topic</span><br><span class="line">  消费者(Consumer)  -  实现pub&#x2F;sub模型.一个consumer &lt;&#x3D;&gt; 1个partition  </span><br><span class="line">4.kafka服务器(broker)  -  接收和处理客户端发送来的请求,对消息进行持久化.</span><br><span class="line">5.备份机制(Replication)  -  高可用.</span><br><span class="line">  副本(partition Replica)  -&gt;  领导者副本(leader Replica) 和 追随者副本(Follower Replica).</span><br><span class="line">  领导者副本(leader Replica) -&gt; 对外提供服务(与客户端进行交互).</span><br><span class="line">  追随者副本(follower Replica) -&gt; 向领导副本发送请求,请求领导者将最新生产的消息发给它,与领导者保持同步.</span><br><span class="line">6.分区机制(Partitioning) - 伸缩性(Scalability).</span><br><span class="line">  1个topic -&gt; n个分区.   分区编号: 0 - n-1.</span><br><span class="line">  消息位移(offset) -&gt; 消息在分区中的位置.</span><br><span class="line">7.数据持久化.</span><br><span class="line">  消息日志(log)  -&gt;  Append only file.顺序I&#x2F;O.</span><br><span class="line">  日志段(Log Segment)  -&gt; 一个log &#x3D;&gt; n个日志段.</span><br><span class="line">                         当日志段被写满后,kafka会自动且分出一个新的日志段.</span><br><span class="line">  kafka在后台通过定时任务检查老的日志段能否被删除,从而实现回收磁盘空间的目的.</span><br><span class="line">  tips:  log文件粒度 -&gt; &lt;topic,partiton,segment(段)&gt;</span><br><span class="line">8.重平衡(Rebalance).</span><br><span class="line">  消费者Group中的消费者个数发生变化,topic对应的kafka broker coordinator会进行协调操作(分区的重分配).</span><br><span class="line">9.消费者位移(Consumer Offset) -&gt; 记录消费者消费了分区的哪个位置.</span><br></pre></td></tr></table></figure>
<h3 id="kafka为啥这么快"><a href="#kafka为啥这么快" class="headerlink" title="kafka为啥这么快"></a>kafka为啥这么快</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.伸缩性 -&gt; 分区.</span><br><span class="line">2.日志文件 -&gt; 追加写.</span><br><span class="line">3.PageCache + Mmap -&gt; zero copy.</span><br><span class="line">4.broker reactor方式处理客户端请求.</span><br></pre></td></tr></table></figure>
<h3 id="kafka版本迭代"><a href="#kafka版本迭代" class="headerlink" title="kafka版本迭代"></a>kafka版本迭代</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0.7  -&gt;  最初版本,只提供了最基础的消息队列功能.</span><br><span class="line">0.8  -&gt;  副本机制.</span><br><span class="line">0.9  -&gt;  安全认证&#x2F;权限,使用java重写新版本消费者API.</span><br><span class="line">0.10.0  -&gt;  kafka streams.</span><br><span class="line">0.11.0  -&gt;  幂等性Producer API与事务(Transaction)API.保证Kafka Streams流处理的正确性.</span><br></pre></td></tr></table></figure>
<h2 id="kafka基本使用"><a href="#kafka基本使用" class="headerlink" title="kafka基本使用"></a>kafka基本使用</h2><h3 id="linux操作系统"><a href="#linux操作系统" class="headerlink" title="linux操作系统"></a>linux操作系统</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">I&#x2F;O模型  -&gt;  阻塞式I&#x2F;O(多线程),非阻塞式I&#x2F;O(socket某个操作不能满足,直接返回错误),I&#x2F;O多路复用(selector,epoll -&gt; reactor),信号驱动I&#x2F;O,异步I&#x2F;O.</span><br><span class="line">  tips:  kafka 底层使用Java的selector,selector在linux上的实现机制为epoll,在windows上的实现机制为select.</span><br><span class="line">网络传输效率 -&gt; kafka的消息是存储在log file中.</span><br><span class="line">  tips: 磁盘 -&gt; 主存 -&gt; 用户进程内存 -&gt; 主存 -&gt; socket,内核态和用户态之间的数据拷贝非常昂贵.</span><br><span class="line">  tips: linux部署kafka使用零拷贝(zero copy)技术,实现快速数据传输.</span><br><span class="line">  zero copy -&gt; 减少了系统空间与用户空间之间的数据拷贝.</span><br><span class="line">            -&gt; FileChannel.transferTo</span><br><span class="line">            -&gt; FileChannel.transferFrom</span><br><span class="line">磁盘  -&gt; kafka log file append only,顺序读写,使用普通的机械硬盘就可以了.</span><br><span class="line">        假设每天有一亿条1KB大小的消息,保存2份,预留空间为10%,压缩比为0.75,消息存储时间为2周.</span><br><span class="line">        总的空间大小为 1亿 * 1KB * 2 * (1+10%) * 14 * 0.75  &#x2F;1000 &#x2F;1000 &#x3D; 2.25TB .</span><br><span class="line">        tips: 磁盘可以组成raid实现failover.</span><br><span class="line">带宽  -&gt; 1Gbps的千兆网络,每秒处理并发送1Gb数据,假设kafka服务器最多会用到70%的带宽资源,单台服务器大约用到700Mb的带宽资源.</span><br><span class="line">         每台kfaka服务器的带宽峰值为700Mb,预留2&#x2F;3的资源,每台服务器大约使用700&#x2F;3&#x3D;240Mb的资源.</span><br><span class="line">         若1小时需要处理1Tb数据量,即每秒2336Mb的数据,需要10台kafka服务器,再加上额外的2分复制,一共需要30台服务器.</span><br><span class="line">mmap  -&gt; </span><br><span class="line">      1.java 的MappedByteBuffer 将文件直接与内存用户空间的某个page进行映射.</span><br><span class="line">      2.mmap -&gt; 将用户空间与内核空间都指向呢个page.</span><br><span class="line">      及减少了用户空间和内核空间之间的数据拷贝.</span><br><span class="line">    tips: linux sendfile -&gt; </span><br><span class="line">          以 文件 -&gt;内存 -&gt; socket为例,sendfile 减少了内核到用户，内核与内核之间的拷贝.</span><br></pre></td></tr></table></figure>
<h3 id="kafka-broker-参数配置"><a href="#kafka-broker-参数配置" class="headerlink" title="kafka broker 参数配置"></a>kafka broker 参数配置</h3><h4 id="broker端参数"><a href="#broker端参数" class="headerlink" title="broker端参数"></a>broker端参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.log.dirs  -&gt;  &#x2F;home&#x2F;kafka1,&#x2F;home&#x2F;kafka2...  </span><br><span class="line">  1.不同的目录可以挂载不同的物理磁盘.</span><br><span class="line">    kafka 1.1 版本引入failover,坏掉的磁盘数据可以转移到其它正常的磁盘上.</span><br></pre></td></tr></table></figure>
<h4 id="broker连接参数"><a href="#broker连接参数" class="headerlink" title="broker连接参数"></a>broker连接参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">broker连接相关的参数.</span><br><span class="line">  listeners  -&gt;  外部连接者通过什么协议访问指定主机名和端口开放的kafka服务.格式为&lt;协议名称,主机名,端口号&gt;</span><br><span class="line">                 协议: PLAINTEXT(明文),SSL(密文)</span><br><span class="line">  advertised.listeners  -&gt;  外网使用.</span><br></pre></td></tr></table></figure>
<h4 id="zookeeper配置"><a href="#zookeeper配置" class="headerlink" title="zookeeper配置"></a>zookeeper配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zookeeper -&gt; 分布式协调框架.</span><br><span class="line">  元数据 -&gt; 运行的broker,创建的topic,topic的分区,分区的leader副本.</span><br><span class="line">zookeeper.connect -&gt; zk1:2181,zk2:2181,zk3:2181</span><br><span class="line">  使用zookeeper的chroot(change root directory)  -&gt;  zk1:2181,zk2:2181,zk3:2181&#x2F;kafka</span><br></pre></td></tr></table></figure>
<h4 id="topic管理"><a href="#topic管理" class="headerlink" title="topic管理"></a>topic管理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auto.create.topics.enable(false) -&gt; 自动创建topic(topic不存在时).</span><br><span class="line">unclean.leader.election.enable(false) -&gt; unclean leader 选举</span><br><span class="line">  tips:  未在isr中的副本有机会成为leader.  </span><br><span class="line">auto.leader.rebalance.enable(false) -&gt; 定期对所有的副本进行leader重新选举</span><br></pre></td></tr></table></figure>
<h4 id="数据留存方面"><a href="#数据留存方面" class="headerlink" title="数据留存方面"></a>数据留存方面</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">log.retention.&#123;hours|minutes|ms&#125;  -&gt;  消息数据被保存多长时间,ms优先级最高.</span><br><span class="line">    log.retention.hours&#x3D;168 -&gt; 默认保存7天的数据</span><br><span class="line">log.retention.bytes  -&gt;  broker为消息保存的总磁盘容量大小</span><br><span class="line">    tips:若超过阈值,会删除老的日志段.</span><br><span class="line">    tips: 大小是指分区大小</span><br><span class="line">      日志存储 -&gt; topic1-partion0&#x2F;1.log,topic1-partion0&#x2F;2.log.</span><br><span class="line">message.max.byte  -&gt;  broker能接收的最大消息大小</span><br></pre></td></tr></table></figure>
<h4 id="topic级别参数"><a href="#topic级别参数" class="headerlink" title="topic级别参数"></a>topic级别参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tips: topic参数(客户端创建&#x2F;修改topic时配置)会覆盖broker参数.</span><br><span class="line">retention.&#123;hours|minutes|ms&#125;: 消息被保存的时长,默认7天.</span><br><span class="line">retention.bytes: partition预留多大的磁盘空间.</span><br><span class="line">max.message.bytes: topic的最大消息的大小.</span><br><span class="line">tips: kafka-topic.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1  --replication-factor 1 --config retention.ms&#x3D;15552000000 --config max.message.bytes&#x3D;524288</span><br><span class="line">tips: kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes&#x3D;10485760</span><br></pre></td></tr></table></figure>
<h4 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.-Xms -&gt; 6GB</span><br><span class="line">  tips: kafka broker与客户端交互时候会创建大量的ByteBuffer实例.</span><br><span class="line">        mmap -&gt; MappedByteBuffer</span><br><span class="line">2.垃圾回收器.</span><br><span class="line">  java7 -&gt; -XX:+UseCurrentMarkSweepGC (cpu多)</span><br><span class="line">        -&gt; -XX:+UseParallelGC(cpu少)</span><br><span class="line">  java8 -&gt; G1(full gc次数相对较少,参数调整相对较少)</span><br><span class="line">kfaka的环境变量设置.</span><br><span class="line">  KAFKA_HEAP_OPTS: 指定堆大小</span><br><span class="line">  KAFKA_JVM_PERFORMANCE_OPTS: 指定GC参数</span><br></pre></td></tr></table></figure>
<h4 id="操作系统参数"><a href="#操作系统参数" class="headerlink" title="操作系统参数"></a>操作系统参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.ulimit -n &lt;n&gt; -&gt; 设置文件描述符阈值.</span><br><span class="line">  tips: 主要是socket数量.</span><br><span class="line">2.文件系统类型  -&gt;  xfs.</span><br><span class="line">3.swap -&gt; 接近于0(linux oom killer).</span><br><span class="line">4.flush落盘时间(默认5秒) -&gt; message先写在操作系统的虚拟内存的page中(mmap),随后操作系统根据LRU算法定期的将脏页追加到log file上.</span><br></pre></td></tr></table></figure>
<h2 id="客户端实践及原理剖析"><a href="#客户端实践及原理剖析" class="headerlink" title="客户端实践及原理剖析"></a>客户端实践及原理剖析</h2><h3 id="为什么分区"><a href="#为什么分区" class="headerlink" title="为什么分区"></a>为什么分区</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">1.负载均衡(load balance)+高吞吐量.</span><br><span class="line">2.分区策略配置.</span><br><span class="line"> 生产者端: partitioner.class -&gt; org.apache.kafka.clients.producer.Partitioner. partition()与close().</span><br><span class="line">  &#x2F;&#x2F; Cluster -&gt; 集群信息(kafka集群有多少主题,多少broker.) </span><br><span class="line">  int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);</span><br><span class="line">3.分区策略.</span><br><span class="line">  Round-robin(最常用).</span><br><span class="line">  Randomness.</span><br><span class="line">  Randomness实现:</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);</span><br><span class="line">    return ThreadLocalRandom.current().nextInt(partitions.size());</span><br><span class="line">  Key-ordering: 按key分区</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);</span><br><span class="line">    return Math.abs(key.hashCode()) % partitions.size();    </span><br><span class="line">  地理位置分区:</span><br><span class="line">    List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic);</span><br><span class="line">    return partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();</span><br></pre></td></tr></table></figure>
<h3 id="生产者压缩算法"><a href="#生产者压缩算法" class="headerlink" title="生产者压缩算法"></a>生产者压缩算法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1.何时压缩?</span><br><span class="line">  1.生产者:  compression.type  -&gt; gzip</span><br><span class="line">  2.broker.</span><br><span class="line">    1.broker与producer的压缩算法不一致,broker会先对消息按照producer的算法解压,再按照broker的算法压缩.</span><br><span class="line">    2.broker端发生消息格式转换.</span><br><span class="line">2.何时解压缩?</span><br><span class="line">  1.消费者: 解压缩.</span><br><span class="line">  2.broker: 解压缩消息,对消息进行验证.</span><br><span class="line">3.支持的压缩算法.</span><br><span class="line">  1.gzip,snappy,lz4.</span><br><span class="line">  2.Zstandard(2.1.0).</span><br><span class="line">4.压缩指标.</span><br><span class="line">  压缩比 + 压缩吞吐量(压缩速度).</span><br><span class="line">5.压缩原因 -&gt; 时间(cpu)换取空间(带宽).</span><br></pre></td></tr></table></figure>
<h3 id="无消息丢失配置"><a href="#无消息丢失配置" class="headerlink" title="无消息丢失配置"></a>无消息丢失配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">1.已提交的消息(committed message).</span><br><span class="line">  kafka的若干个broker成功地接收到一条消息并写入日志文件中,它们会告诉生产者程序这条消息已成功提交.</span><br><span class="line">  acks -&gt; 0  不确认</span><br><span class="line">  acks -&gt; 1  leader partition 确认</span><br><span class="line">  acks -&gt; all min.insync.replicas(ISR)确认</span><br><span class="line">2.有限度的持久化保证.</span><br><span class="line">  有限度 -&gt; 消息保存在N个kafka broker上,N个broker服务器只要有一个服务器存活,那么消息永远不会丢失.</span><br><span class="line">3.消息丢失案例.</span><br><span class="line">  1.生产者程序丢失数据.</span><br><span class="line">    网络抖动,消息太大(message.max.byte).</span><br><span class="line">  2.Broker端丢失数据.</span><br><span class="line">    全部broker服务器宕机.或消息过期,log过大导致删除.</span><br><span class="line">  3.消费者程序丢失数据.</span><br><span class="line">    tips: 都是应用层将消息做缓存稍后处理,先提交位移(手&#x2F;自动)造成.</span><br><span class="line">4.最佳实践(kafka无消息丢失配置).</span><br><span class="line">  1.生产者端.</span><br><span class="line">    producer.send(msg,callback);  &#x2F;&#x2F;查看消息格式是否错误</span><br><span class="line">    asks &#x3D; all</span><br><span class="line">    retries(重试) &#x3D; 5</span><br><span class="line">  2.kafka broker端.</span><br><span class="line">    unclean.leader.election.enable &#x3D; false (不在ISR中的副本能否成为leader)</span><br><span class="line">    replication.factor &#x3D; 3(消息副本数)</span><br><span class="line">    min.insync.replicas &#x3D; 2(acks&#x3D;all的数量).  -&gt; replication.factor &#x3D; min.insync.replicas + 1</span><br><span class="line">  3.consumer端.</span><br><span class="line">    enable.auto.commit &#x3D; false -&gt;  消费端自动提交.</span><br></pre></td></tr></table></figure>
<h3 id="客户端高级功能-不常用"><a href="#客户端高级功能-不常用" class="headerlink" title="客户端高级功能(不常用)"></a>客户端高级功能(不常用)</h3><h4 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">1.生产者拦截器.</span><br><span class="line">  拦截点:  发送消息前,提交消息后.</span><br><span class="line">  tips: interceptor的onSend和onAcknowledgement不是在一个线程中调用,必须要保证线程安全.</span><br><span class="line">        onSend和send方法是在一个线程中,不要在onSend中放太重的逻辑,否则会影响tps.</span><br><span class="line">  for example:</span><br><span class="line">    Properties props &#x3D; new Properties();</span><br><span class="line">    List&lt;String&gt; interceptors &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">    interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); &#x2F;&#x2F; 拦截器1</span><br><span class="line">    interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); &#x2F;&#x2F; 拦截器2</span><br><span class="line">    props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line">    ……</span><br><span class="line">2.消费者拦截器.</span><br><span class="line">  拦截点:  消费消息前,提交偏移量后.</span><br><span class="line">  interceptor.classes -&gt; org.apache.kafka.clients.consumer.ConsumerInterceptor</span><br><span class="line">  tisp: onConsume&#x2F;onCommit</span><br><span class="line">3.典型使用场景.</span><br><span class="line">  客户端监控,端到端系统性能检测,消息审计.</span><br><span class="line"> for example: 端到端系统性能检测和消息审计.</span><br><span class="line">  1.审计数据保存到redis中.</span><br><span class="line">  2.生产端拦截器.</span><br><span class="line">    public class AvgLatencyProducerInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;</span><br><span class="line">      private Jedis jedis; &#x2F;&#x2F; 省略Jedis初始化</span><br><span class="line">      @Override</span><br><span class="line">      public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;</span><br><span class="line">          jedis.incr(&quot;totalSentMessage&quot;);</span><br><span class="line">          return record;</span><br><span class="line">      &#125;</span><br><span class="line">      @Override</span><br><span class="line">      public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">      &#125;</span><br><span class="line">      @Override</span><br><span class="line">      public void close() &#123;</span><br><span class="line">      &#125;</span><br><span class="line">      @Override</span><br><span class="line">      public void configure(Map&lt;java.lang.String, ?&gt; configs) &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  3.消费端拦截器.</span><br><span class="line">    public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor&lt;String, String&gt; &#123;</span><br><span class="line">        private Jedis jedis; &#x2F;&#x2F;省略Jedis初始化</span><br><span class="line">        @Override</span><br><span class="line">        public ConsumerRecords&lt;String, String&gt; onConsume(ConsumerRecords&lt;String, String&gt; records) &#123;</span><br><span class="line">            long lantency &#x3D; 0L;</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                lantency +&#x3D; (System.currentTimeMillis() - record.timestamp());</span><br><span class="line">            &#125;</span><br><span class="line">            jedis.incrBy(&quot;totalLatency&quot;, lantency);</span><br><span class="line">            long totalLatency &#x3D; Long.parseLong(jedis.get(&quot;totalLatency&quot;));</span><br><span class="line">            long totalSentMsgs &#x3D; Long.parseLong(jedis.get(&quot;totalSentMessage&quot;));</span><br><span class="line">            jedis.set(&quot;avgLatency&quot;, String.valueOf(totalLatency &#x2F; totalSentMsgs));</span><br><span class="line">            return records;</span><br><span class="line">        &#125;</span><br><span class="line">        @Override</span><br><span class="line">        public void onCommit(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        @Override</span><br><span class="line">        public void close() &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        @Override</span><br><span class="line">        public void configure(Map&lt;String, ?&gt; configs) &#123;&#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h4 id="java生产者管理tcp连接"><a href="#java生产者管理tcp连接" class="headerlink" title="java生产者管理tcp连接"></a>java生产者管理tcp连接</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1.多路复用请求(multiplexing request),多个数据流复用一个连接.</span><br><span class="line">  TCP的多路复用请求会在一个物理连接上创建若干个虚拟连接,每个虚拟连接负责流转各自对应的数据流.</span><br><span class="line">2.何时创建tcp连接?</span><br><span class="line">  Producer producer&#x3D;new KafkaProducer(props);</span><br><span class="line">  1.KafkaProducer 实例创建时启动 Sender 线程，从而创建与 bootstrap.servers 中所有 Broker 的 TCP 连接。</span><br><span class="line">  2.KafkaProducer 实例首次更新元数据信息之后，还会再次创建与集群中所有 Broker 的 TCP 连接。</span><br><span class="line">  3.如果 Producer 端发送消息到某台 Broker 时发现没有与该 Broker 的 TCP 连接，那么也会立即创建连接。</span><br><span class="line">3.TCP连接可能创建的两个地方.</span><br><span class="line">  1.producer更新了连接集群元数据. -&gt; metadata请求</span><br><span class="line">    1.metadata.max.age.ms -&gt; producer拉取元数据信息的定期时间</span><br><span class="line">    2.当 Producer 尝试给一个不存在的主题发送消息时.</span><br><span class="line">  2.调用send方法,发现与目标broker未连接(目标broker没配置在bootstrap.servers中).</span><br><span class="line">4.何时关闭tcp连接?</span><br><span class="line">  1.用户主动关闭.</span><br><span class="line">    producer.close();.</span><br><span class="line">    kill -9 &lt;process_id&gt;;  &#x2F;&#x2F; 发送信号</span><br><span class="line">  2.kafka自动关闭(passive close).</span><br><span class="line">    producer 设置connections.max.idle.ms  -&gt;  broker端会在超时后关闭掉tcp连接.</span><br></pre></td></tr></table></figure>
<h3 id="幂等生产者和事务"><a href="#幂等生产者和事务" class="headerlink" title="幂等生产者和事务"></a>幂等生产者和事务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.至少一次(at least once): 消息不会丢失,但有可能被重复发送.</span><br><span class="line">  重试机制: 重试是因为未收到broker的应答,而不是消息格式不正确、消息太大等错误.</span><br><span class="line">2.最多一次(at most once): 消息可能丢失.</span><br><span class="line">    将重试次数设置为0.</span><br></pre></td></tr></table></figure>
<h4 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">幂等  -&gt;  操作&#x2F;函数执行多次,得到的结果都是不变的.</span><br><span class="line">0.11 -&gt;  producerProps.put(&quot;enable.idempotence&quot;,true);</span><br><span class="line">kafka的broker端会保留一些字段,当producer发送具有相同字段值的消息后,broker判断消息是否重复,若已经重复,则把它们丢弃掉.</span><br><span class="line">tips: 幂等性只能保证某个主题的一个分区上不会出现重复消息.</span><br><span class="line">            幂等性只能保证单会话(Producer进程)上的幂等性.</span><br></pre></td></tr></table></figure>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">ACID -&gt; 原子性(Atomicity),一致性(Consistency),隔离性(Isolation),持久性(Durability).</span><br><span class="line"><span class="number">0.11</span> -&gt; kafka支持事务-&gt;read committed.</span><br><span class="line">        enable.idempotence -&gt;<span class="keyword">true</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事务操作</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">producer.initTransactions();</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    producer.beginTransaction();</span><br><span class="line">    producer.send(record1);</span><br><span class="line">    producer.send(record2);</span><br><span class="line">&#125;<span class="keyword">catch</span>(KafkaException e)&#123;</span><br><span class="line">    producer.abortTransaction();</span><br><span class="line">&#125;</span><br><span class="line">....</span><br><span class="line">consumer端</span><br><span class="line">consumerProps.put(<span class="string">"isolation.level"</span>,<span class="string">"read_committed"</span>);</span><br><span class="line"></span><br><span class="line">事务与幂等性区别</span><br><span class="line"><span class="number">1</span>.事务可以实现跨分区、会话间的幂等性.</span><br><span class="line">kafka事务主要用于 consumer和producer在一个线程中处理处理上下游这种.</span><br></pre></td></tr></table></figure>
<h3 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">1.Consumer Group  -&gt;  kafka提供的可扩展且具有容错性的消费者机制.</span><br><span class="line">2.标识符  -&gt;  group.id</span><br><span class="line">3.对应关系.</span><br><span class="line">  n topic -&gt; n consumer group</span><br><span class="line">  1 consumer group -&gt; n consumer</span><br><span class="line">  1 consumer -&gt; 1 topic&#39;s leader partition</span><br><span class="line">4.kafka consumer group vs 传统的消息队列.</span><br><span class="line">    传统的消息队列缺陷  -&gt;  消息一旦被某个&#x2F;些消费者消费,消息会从队列中删除.</span><br><span class="line">                      -&gt;  消费者必须订阅整个主题,并且会消费该主题的所有消息.</span><br><span class="line">5.offset(消费者 位移). </span><br><span class="line">  Consumer Group -&gt; &lt;partition,offset(long)&gt; 记录分区与消费者组的位移关系.</span><br><span class="line">  tips: 消费者提交的offset为消费的msg的offset+1</span><br><span class="line">6.offset 新老版本差异.</span><br><span class="line">  老版本: offset 存在zookeeper中.</span><br><span class="line">  新版本: offset 存在kafka broker(__consumer_offsets)中,因为zookeeper不适合大吞吐量的写操作,而Consumer Group的位移更新是一个非常频繁的操作.</span><br><span class="line">7.Reblance -&gt; 一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区.</span><br><span class="line">  Reblance 触发条件.</span><br><span class="line">    1.组成员变更. consumer加入或离开组,consumer实例奔溃被踢出组.</span><br><span class="line">    2.订阅的主题数发生变更.</span><br><span class="line">      consumer.subscribe(Pattern.compile(&quot;t.*c&quot;));</span><br><span class="line">      当consumer运行时候,有一个满足与该正则表达式的主题被创建,Group会发生再均衡.</span><br><span class="line">    3.订阅主题的分区数发生变化.</span><br><span class="line">      kafka只允许增加一个主题的分区数.</span><br><span class="line">  tips: Reblance过程类似java vm 垃圾回收的STW,所有的Consumer实例都会停止消费,直到Reblance完成.</span><br></pre></td></tr></table></figure>
<h3 id="kafka-新版本位移存储"><a href="#kafka-新版本位移存储" class="headerlink" title="kafka 新版本位移存储"></a>kafka 新版本位移存储</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1.位移主题(offsets topic) -&gt;  __consumer_offsets</span><br><span class="line">2.消息格式  -&gt; kafka自定义,用户不能随意修改</span><br><span class="line">           tips: 用户如果随意的向主题写消息,kafka内部将会无法成功解析,会造成broker的奔溃.</span><br><span class="line">          -&gt; &lt;K,V&gt; -&gt; k -&gt; consumer group id  + topic  + partition</span><br><span class="line">                   -&gt; v -&gt; offset</span><br><span class="line">3.位移主题保存的其它2种格式.</span><br><span class="line">  1.consumer group(注册consumer group).</span><br><span class="line">  2.删除group过期位移,删除group信息(tombstone信息).</span><br><span class="line">4.位移主题(__consumer_offsets)默认的分区数是50(offsets.topic.num.partitions).</span><br><span class="line">    分区副本数是3(offsets.topic.replication.factor).</span><br><span class="line">5.位移的写入.</span><br><span class="line">  enable.auto.commit -&gt; 自动&#x2F;手动提交位移.</span><br><span class="line">  auto.commit.interval.ms -&gt; 自动提交位移时间间隔.</span><br><span class="line">6.kafka采用Compaction策略删除位移主题中的过期消息.</span><br><span class="line">  compaction操作 -&gt; 删除同一个key对应的old offset数据.</span><br><span class="line">  compaction线程 -&gt; log cleaner.  </span><br><span class="line">  tips: </span><br><span class="line">    while(true)&#123;</span><br><span class="line">      consumer.poll(true) &#x2F;&#x2F; 这里会判断提交位移时间间隔是否达到,若达到,即使不能poll到message,也会提交offset,所以offset主题会存在很多相同的offset数据.</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="Coordinator-协调者"><a href="#Coordinator-协调者" class="headerlink" title="Coordinator(协调者)"></a>Coordinator(协调者)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.coordinator -&gt; 为consumer group服务,负责为group执行reblance以及提供位移管理和组成员管理等.</span><br><span class="line">tips: conusmer提交位移是向coordinator所在的broker提交位移.</span><br><span class="line">      Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。</span><br><span class="line">2.consumer 如何找到 group coordinator?  </span><br><span class="line">    &#x2F;&#x2F;根据groupId,找到位移主题对应的分区</span><br><span class="line">    1.partitionId&#x3D;Math.abs(groupId.hashCode() % offsetsTopicPartitionCount:50)</span><br><span class="line">    2.找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator</span><br><span class="line">  tips: tips: 1个broker是多个消费者组的coordinator.</span><br><span class="line">3.Rebalance三个弊端.</span><br><span class="line">  1.Rebalance 影响 Consumer 端 TPS(stw).</span><br><span class="line">  2.Rebalance 很慢.</span><br><span class="line">  3.Rebalance 效率不高(改进-&gt;sticky).    </span><br><span class="line">4.Rebalance发生避免.</span><br><span class="line"> tips: 对consumer group的consumer数量减少做避免.</span><br><span class="line">  1.当consumer与coordinator在 session.timeout.ms(6s)内未通信(心跳),说明consumer已死,coordinator会引发新的一轮再均衡.</span><br><span class="line">  2.heartbeat.interval.ms(2s,重试2次)  -&gt;  客户端发送心跳的频率  </span><br><span class="line">    tips: Coordinator会将REBALANCE_NEEDED 标志封装进心跳请求的响应体,这个表示表示是否正在rebalance.</span><br><span class="line">  3.max.poll.interval.ms(5分钟)</span><br><span class="line">    若消费者5分钟没有处理完poll的数据,会向coordinator发起leaveGroup请求.</span><br><span class="line"> tips:针对consumer消费时间过长,导致消费者被剔出.</span><br><span class="line">    max.poll.interval.ms 设置大点.</span><br></pre></td></tr></table></figure>
<h3 id="kafka位移提交"><a href="#kafka位移提交" class="headerlink" title="kafka位移提交"></a>kafka位移提交</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">1.consumer端记录的位移是下一条消息(未消费)的位移.</span><br><span class="line">  tips: consumer将其消费的所有分区的位移提交到kafka broker服务器上,kafka会认为小于位移的消息都成功消费.</span><br><span class="line">2.位移分类.</span><br><span class="line">用户     -&gt; 自动提交,手动提交(enable.auto.commit+auto.commit.interval.ms(自动提交的间隔)).</span><br><span class="line">            tips:kafka会保证在开始调用poll方法时候,提交上次poll返回的所有消息.</span><br><span class="line">            tips: 若自动提交时间间隔内发生rebalance,会导致部分消息重新消费.</span><br><span class="line">           手动提交: consumer.commitSync();</span><br><span class="line">消费者   -&gt; 同步提交,异步提交.</span><br><span class="line">           异步提交:</span><br><span class="line">           consumer.commitAsync((offset,exception)-&gt;&#123;</span><br><span class="line">             if(exception!&#x3D;null)&#123;</span><br><span class="line">               handleException(exception);</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;);</span><br><span class="line">tips:同步提交,失败可以重试(stw),异步提交失败不能重试(因为消费者偏移量可能变了).</span><br><span class="line">tips:同步提交可以规避这些瞬时错误,如网络抖动,broker端gc等.</span><br><span class="line">3.同步和异步相结合</span><br><span class="line">     try&#123;</span><br><span class="line">       while(true)&#123;</span><br><span class="line">           ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(Duration.ofSeconds(1));</span><br><span class="line">           process(records);</span><br><span class="line">           commitAsync(); &#x2F;&#x2F; 异步提交,避免程序阻塞</span><br><span class="line">       &#125;catch(Exception e)&#123;</span><br><span class="line">          handle(e);</span><br><span class="line">       &#125;finally&#123;</span><br><span class="line">         try&#123;</span><br><span class="line">           consumer.commitSync(); &#x2F;&#x2F;consumer关闭前,提交正确的位移数据</span><br><span class="line">         &#125;finally&#123;</span><br><span class="line">           consumer.close();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">4.consumer批量提交控制.</span><br><span class="line">tips: 由于poll操作返回的消息数据不太确定,所以对每次poll获取的消息进行提交并不是一个合理的选择.</span><br><span class="line">  private Map offsets &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">  int count&#x3D;0;</span><br><span class="line">  ……</span><br><span class="line">  while (true) &#123;            </span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records &#x3D;   consumer.poll(Duration.ofSeconds(1));            </span><br><span class="line">    for (ConsumerRecord&lt;String, String&gt; record: records) &#123;                        </span><br><span class="line">      process(record);  &#x2F;&#x2F; 处理消息                        </span><br><span class="line">      &#x2F;&#x2F; +1 because 消费者保存比较大的位移</span><br><span class="line">      offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；   </span><br><span class="line">      if（count % 100 &#x3D;&#x3D; 0）                                    </span><br><span class="line">        consumer.commitAsync(offsets, null); &#x2F;&#x2F; 回调处理逻辑是null                        </span><br><span class="line">        count++;  </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">5.自动提交的逻辑是在consumer.poll方法中.</span><br><span class="line">  1.判断距离上次提交的时间差是否大于设定间隔.</span><br></pre></td></tr></table></figure>
<h3 id="CommitFailedException"><a href="#CommitFailedException" class="headerlink" title="CommitFailedException"></a>CommitFailedException</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">CommitFailedException -&gt; 客户端提交位移时出现了异常(不可恢复).</span><br><span class="line">tips:若是可恢复的异常,提交位移的api可以自动规避,若consume.commitSync方法支持重试功能.</span><br><span class="line">产生原因:</span><br><span class="line">  commit offset操作时候,发现已发送rebalance,该分区被分配到同消费者组的其它消费者上.</span><br><span class="line">  解决方式:</span><br><span class="line">        防止再均衡</span><br><span class="line">           max.poll.interval.ms  </span><br><span class="line">           max.poll.records   </span><br><span class="line">产生场景一:</span><br><span class="line">  Properties pros&#x3D;new Properties();</span><br><span class="line">  props.put(&quot;max.poll.interval.ms&quot;,5000);</span><br><span class="line">  ......</span><br><span class="line">  consumer.subscribe(Arrays.asList(&quot;test-topic&quot;));</span><br><span class="line">  while(true)&#123;</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records &#x3D;  consumer.poll(Duration.ofSeconds(1));</span><br><span class="line">    Thread.sleep(6000l);</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">  &#125;</span><br><span class="line"> 优化: </span><br><span class="line">    1.缩短单条消息的处理时间.</span><br><span class="line">    2.增加Consumer端允许下游系统消费一批消息的最大时长(max.poll.interval.ms&#x2F;session.timeout.ms(0.10.1.0之前)).</span><br><span class="line">    3.减少下游系统一次性消费的消息总数(max.poll.records).</span><br><span class="line">    4.下游系统使用多线程加速消费.</span><br></pre></td></tr></table></figure>
<h3 id="多线程开发消费者实例"><a href="#多线程开发消费者实例" class="headerlink" title="多线程开发消费者实例"></a>多线程开发消费者实例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.10.1.0 -&gt; KafkaConsumer -&gt; 用户主线程(new Consumer()呢个线程)和心跳线程.</span><br><span class="line">老版本 -&gt;  Consumer是多线程架构,每个 Consumer 实例在内部为所有订阅的主题分区创建对应的消息获取线程(Fetcher线程).</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/consumer-multi-thread.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">消息获取  +  消息处理</span><br><span class="line">n个topic partition &lt;-&gt; n个consumer.</span><br><span class="line">consumer 将消息处理任务提交到线程池中.</span><br><span class="line">优点: 伸缩性好,可独立扩展消息获取线程数和Worker线程数.</span><br><span class="line">缺点: 难以维护分区消息消费顺序,</span><br><span class="line">     处理链路拉长,不易于位移提交管理.</span><br></pre></td></tr></table></figure>
<h3 id="Java消费者如何管理TCP连接"><a href="#Java消费者如何管理TCP连接" class="headerlink" title="Java消费者如何管理TCP连接"></a>Java消费者如何管理TCP连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.消费者建立的三类TCP连接.</span><br><span class="line">  KafkaConusmer.poll</span><br><span class="line">    1.METADATA.</span><br><span class="line">    2.FIND_COORDINATOR.</span><br><span class="line">    3.FETCH(消费者获取消息).</span><br><span class="line">2.何时关闭tcp连接.</span><br><span class="line">  1.主动关闭</span><br><span class="line">     kafkaConsumer.close&#x2F;kill</span><br><span class="line">  2.自动关闭.</span><br><span class="line">    connection.max.idle.ms -&gt; 这个应该不是指多长时间没发消息&#x2F;没消费消息,应该是连接断开时间.</span><br></pre></td></tr></table></figure>
<h3 id="消费者组消费进度监控"><a href="#消费者组消费进度监控" class="headerlink" title="消费者组消费进度监控"></a>消费者组消费进度监控</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">消费滞后程度  -&gt;  消费者Lag&#x2F;consumer lag(消费者落后生产者的程度).</span><br><span class="line">监控消费进度:</span><br><span class="line">  1.使用 Kafka 自带的命令行工具 kafka-consumer-groups 脚本。</span><br><span class="line">    $ bin&#x2F;kafka-consumer-groups.sh --bootstrap-server &lt;Kafka broker连接信息&gt; --describe --group &lt;group名称&gt;</span><br><span class="line">  2.使用 Kafka Java Consumer API 编程。</span><br><span class="line">  &#x2F;&#x2F;kafka 2.0.0</span><br><span class="line">  public static Map&lt;TopicPartition, Long&gt; lagOf(String groupID, String bootstrapServers) throws TimeoutException &#123;</span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);</span><br><span class="line">        try (AdminClient client &#x3D; AdminClient.create(props)) &#123;</span><br><span class="line">            ListConsumerGroupOffsetsResult result &#x3D; client.listConsumerGroupOffsets(groupID);</span><br><span class="line">            try &#123;</span><br><span class="line">                Map&lt;TopicPartition, OffsetAndMetadata&gt; consumedOffsets &#x3D; result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);</span><br><span class="line">                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); &#x2F;&#x2F; 禁止自动提交位移</span><br><span class="line">                props.put(ConsumerConfig.GROUP_ID_CONFIG, groupID);</span><br><span class="line">                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">                try (final KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props)) &#123;</span><br><span class="line">                    Map&lt;TopicPartition, Long&gt; endOffsets &#x3D; consumer.endOffsets(consumedOffsets.keySet());</span><br><span class="line">                    return endOffsets.entrySet().stream().collect(Collectors.toMap(entry -&gt; entry.getKey(),</span><br><span class="line">                            entry -&gt; entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                Thread.currentThread().interrupt();</span><br><span class="line">                &#x2F;&#x2F; 处理中断异常</span><br><span class="line">                &#x2F;&#x2F; ...</span><br><span class="line">                return Collections.emptyMap();</span><br><span class="line">            &#125; catch (ExecutionException e) &#123;</span><br><span class="line">                &#x2F;&#x2F; 处理ExecutionException</span><br><span class="line">                &#x2F;&#x2F; ...</span><br><span class="line">                return Collections.emptyMap();</span><br><span class="line">            &#125; catch (TimeoutException e) &#123;</span><br><span class="line">                throw new TimeoutException(&quot;Timed out when getting lag for consumer group &quot; + groupID);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line">  3.使用 Kafka 自带的 JMX 监控指标(推荐)。</span><br><span class="line">    Kafka 消费者提供了一个名为 kafka.consumer:type&#x3D;consumer-fetch-manager-metrics,client-id&#x3D;“&#123;client-id&#125;”的 JMX 指标</span><br><span class="line">    records-lag-max&#x2F;records-lag-min 消费者在测试窗口时间内达到的最大的Lag值与最小的Lead(位移差)值.</span><br><span class="line">    tips: 通过jconsole工具查看.</span><br><span class="line">3.lag分析.</span><br><span class="line">  马太效应 -&gt; lag很大的消费者,lag会越来越大,因为consumer读的慢话，broker已经将数据flush到log文件中,consumer读会从broker文件中读.</span><br></pre></td></tr></table></figure>
<h2 id="深入kafka内核"><a href="#深入kafka内核" class="headerlink" title="深入kafka内核"></a>深入kafka内核</h2><h3 id="kafka副本机制详解"><a href="#kafka副本机制详解" class="headerlink" title="kafka副本机制详解"></a>kafka副本机制详解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.副本优势</span><br><span class="line">  1.提供数据冗余. -&gt; 高可用</span><br><span class="line">  2.提供高伸缩性. </span><br><span class="line">  3.改善数据局部性.   -&gt; 数据放在用户地理位置相近的位置,从而降低系统延时.</span><br><span class="line">  tips: kafka只能满足第一点.</span><br><span class="line">为啥kafka只满足第一点?</span><br><span class="line">  kafka主副本提供读写,而从副本不提供读写.</span><br><span class="line">    1.只有主副本提供读写,可以控制数据实时一致性.(若从副本开放读功能,可能无法读到刚写到主副本的消息)</span><br><span class="line">    2.单调读一致性.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/kafka-replica.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.follower Replica   异步地从leader Replica拉取消息,append 到自己的副本日志中.</span><br><span class="line">2. leader Replica挂了,kafka依托于zookeeper实时感知,会对该分区进行新一轮领导者选择,从follower中选出一个leader,当原leader副本归来时,只能作为follower.</span><br></pre></td></tr></table></figure>
<h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ISR  -&gt; In-sync Replicas(在同步副本集合中)  与leader副本实时同步的副本们.</span><br><span class="line">tips:ISR 不只是追随者副本集合，它必然包括 Leader 副本。甚至在某些情况下，ISR 只有 Leader 这一个副本</span><br><span class="line">replica.lag.time.max.ms(10秒)  -&gt;Follower 副本落后 Leader 副本的时间超过 10 秒，leader会提出这个follower.</span><br><span class="line">tips: OSR -&gt; Out-sync Relicas,被踢出的副本集合.</span><br><span class="line">unclean 选举 -&gt; unclean.leader.election.enable -&gt; 未在ISR中的副本也可以选举为leader副本.</span><br></pre></td></tr></table></figure>
<h3 id="kafka-请求处理"><a href="#kafka-请求处理" class="headerlink" title="kafka 请求处理"></a>kafka 请求处理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.Apache Kafka定义的客户端通信协议.</span><br><span class="line">  PRODUCE  -&gt;  生产信息</span><br><span class="line">  FETCH    -&gt;  消费消息</span><br><span class="line">  METADATA -&gt;  获取kafka集群元数据信息</span><br><span class="line">  FindCoordinator  -&gt; 消费者获取coordinator</span><br><span class="line">  ....</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/kafka-reactor.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2.请求处理方案.</span><br><span class="line">  1.顺序处理请求.</span><br><span class="line">  2.一个请求一个线程. -&gt; 创建线程开销极大.</span><br><span class="line">  3.Reactor模式.(redis,kafka) -&gt;  事件驱动架构,适用于多个客户端向服务器发送请求场景.</span><br><span class="line">3.kafka reactor模式参数配置.</span><br><span class="line">  1.num.network.threads   -&gt;   网络线程池的线程数.</span><br><span class="line">  tips: acceptor 采取轮询的方式 将client request 交给网络线程处理.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/kafka-reactor-detail.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">网络线程池(num.network.threads)   -&gt;   acceptors 线程池.</span><br><span class="line">acceptor                              放请求到共享请求队列.</span><br><span class="line">IO线程池(num.io.threads)处理请求. -&gt;   从队列中取出请求,并执行处理.</span><br><span class="line">    PRODUCE   -&gt;   将消息写入到底层的磁盘日志中</span><br><span class="line">    FETCH     -&gt;   从磁盘&#x2F;页缓存中读取消息</span><br><span class="line">I&#x2F;O线程将请求处理的结果(response)发送到网络线程的响应队列中.</span><br><span class="line">网络线程将response发送给对应的客户端.</span><br><span class="line">Purgatory(炼狱)组件  -&gt;  缓存延时请求(Delayed Request) -&gt; 未满足条件不能立刻处理的请求,会放到Purgatory中.</span><br><span class="line">  tips: 设置了acks&#x3D;all 的PRODUCE请求,该请求在message写入leader后,必须等待ISR中所有副本都受到消息后返回.</span><br></pre></td></tr></table></figure>
<h3 id="消费者组Reblance"><a href="#消费者组Reblance" class="headerlink" title="消费者组Reblance"></a>消费者组Reblance</h3><h4 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.组成员数量发生变化. -&gt; 消费者异常剔除</span><br><span class="line">2.订阅主题数量发生变化.</span><br><span class="line">3.订阅主题分区数发生变化.</span><br><span class="line">tips: reblance引发时机主要是消费者异常踢出.</span><br></pre></td></tr></table></figure>
<h4 id="消费端对reblance的感知"><a href="#消费端对reblance的感知" class="headerlink" title="消费端对reblance的感知"></a>消费端对reblance的感知</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.kafka 0.10.1.0之前</span><br><span class="line">  1.消费者心跳请求与poll请求是在一个线程.</span><br><span class="line">  tips: 这种情况下若配置session.timeout.ms&lt;max.poll.interval.ms</span><br><span class="line">        导致心跳请求因为处理消息一直没有时机发,会再次引发Rablance.</span><br><span class="line">kafka 0.10.1.0</span><br><span class="line">1.消费者有专门的心跳线程.</span><br><span class="line">2.重平衡和心跳的关系.</span><br><span class="line">  当coordinator决定开启新一轮重平衡时,会将&quot;REBLANCE_IN_PROCESS&quot;封装到心跳请求的响应中.</span><br><span class="line">  当consumer得到REBLANCE_IN_PROCESS响应时候,知道重平衡已开始.</span><br><span class="line">tips: heartbeat.interval.ms -&gt; 心跳的间隔时间,其实是消费者重平衡通知的频率.</span><br></pre></td></tr></table></figure>
<h4 id="消费者状态机"><a href="#消费者状态机" class="headerlink" title="消费者状态机"></a>消费者状态机</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">State Machine -&gt; 协调者会控制消费者组的状态流转.</span><br><span class="line">kafka为消费者组定义了5种状态.</span><br><span class="line">state                                 组成员数量                位移 </span><br><span class="line"> Empty                                   0               可能存在已提交并尚未过期的位移.     </span><br><span class="line"> Dead                                    0               组元数据信息在协调者端被移除(在位移主题里).</span><br><span class="line">                                                         tips: 可以从coordinator broker日志中看到Removed XXX expired offsets in XXX milliseconds.</span><br><span class="line"> PreparingRebalance                                      消费者组开启重平衡,所有成员需要重新请求加入到消费者组.</span><br><span class="line"> CompletingRebalance                                     所有成员已经加入,各个成员等待分配方案.</span><br><span class="line"> Stable                                                  Rebalance已经完成</span><br></pre></td></tr></table></figure>
<h4 id="消费者端重平衡流程"><a href="#消费者端重平衡流程" class="headerlink" title="消费者端重平衡流程"></a>消费者端重平衡流程</h4><p><img src="/2020/02/07/kafka/join-group.png" alt><br><img src="/2020/02/07/kafka/sync-group.png" alt><br>consumer</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.consumer.</span><br><span class="line">  joinGroup -&gt; 请求: 带上自己想要消费的topic,响应: 自己选没选上leader</span><br><span class="line">  SyncGroup -&gt; leader: 请求: 所有consumer分配好的分区信息. 响应: 所有consumer分配好的分区信息.</span><br><span class="line">tips: 第一个发送JoinGroup请求的成员自动成为领导者.</span><br><span class="line">tips: leader consumer 收集所有成员的订阅信息,根据这些信息,制定具体的分区消费分配方案.</span><br><span class="line">2.leader consumer.</span><br><span class="line">  向协调者发送SyncGroup请求,将具体的分区消费分配方案发给协调者.   -  SyncGroup请求</span><br><span class="line">tips: 在消费者收到的心跳响应中有重平衡标志时候,消费者会有一段缓冲时间用来提交自己的位移,随后再发起(joinGroup,syncGroup)请求.</span><br></pre></td></tr></table></figure>
<p>broker<br><img src="/2020/02/07/kafka/reblance-new-consumer.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景一: 新成员入组</span><br><span class="line">  当协调者收到新的 JoinGroup 请求后，它会通过心跳请求响应的方式通知组内现有的所有成员，强制它们开启新一轮的重平衡.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/reblance-consumer-leave.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">场景二: 组成员主动离开(consumer.close())</span><br><span class="line">  LeaveGroup请求</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/reblance-consumer-dead.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">场景三: 组成员奔溃离组(session.timeout.ms&#x2F;max.poll.timeout.ms)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/reblance-offset.commit.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">场景四: 重平衡时协调者对组内成员提交位移的处理</span><br><span class="line">心跳检测到Reblance时候,若消费者在超时时间内发起请求,则能成功提交位移.</span><br><span class="line">超时时间: rebalance timeout -&gt;默认是 max.poll.interval.ms</span><br></pre></td></tr></table></figure>
<h3 id="kafka控制器"><a href="#kafka控制器" class="headerlink" title="kafka控制器"></a>kafka控制器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">控制器组件(controller)  -&gt;    Apache Kafka 的核心组件。它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。</span><br><span class="line">activeController(jmx指标)  -&gt;  实时监控控制器的存活状态.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/kafka-zookeeper.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kafka controller   -&gt;   第一个在zookeeper中成功创建&#x2F;controller节点的broker被指定为控制器.</span><br><span class="line">控制器职责:</span><br><span class="line">  1.主题管理(创建、删除、增加分区).</span><br><span class="line">    kafka-topics -&gt; 通过控制器完成对kfaka主题创建,删除,分区增加.</span><br><span class="line">  2.分区重分配.</span><br><span class="line">    kafka-reassign-partitions -&gt; 通过控制器对已有主题分区进行细粒度的分配功能.</span><br><span class="line">  3.Preferred领导者选举.</span><br><span class="line">    Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案</span><br><span class="line">  4.集群成员管理(新增broker,broker主动关闭,broker宕机).</span><br><span class="line">    zk Watcher -&gt; Controller 会 Watch 检查Zookeeper的&#x2F;brokers&#x2F;ids节点下的子节点数量变更.</span><br><span class="line">    zk 临时节点 -&gt; 每个 Broker 启动后，会在 &#x2F;brokers&#x2F;ids 下创建一个临时 znode.</span><br><span class="line">  5.数据服务.</span><br><span class="line">    控制器上保存了最全的集群元数据信息(其实就是zk上的数据)，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/controller-data.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka 控制器所保留的数据.</span><br><span class="line">1.所有的主题信息. -&gt; 分区、副本、ISR集合.</span><br><span class="line">2.所有broker信息. -&gt; 运行的broker,关闭的broker.</span><br><span class="line">3.所有涉及运维任务的分区。包括当前正在进行 Preferred 领导者选举以及分区重分配的分区列表。</span><br></pre></td></tr></table></figure>
<h4 id="控制器故障转移-failover"><a href="#控制器故障转移-failover" class="headerlink" title="控制器故障转移(failover)"></a>控制器故障转移(failover)</h4><p><img src="/2020/02/07/kafka/controller-failover.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka 能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器.</span><br></pre></td></tr></table></figure>
<h4 id="控制器内部设计原理"><a href="#控制器内部设计原理" class="headerlink" title="控制器内部设计原理"></a>控制器内部设计原理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">多线程</span><br><span class="line">  controller broker 会与其它的broker建立socket连接.一个连接一个线程.</span><br><span class="line">  controller broker 会对zookeeper的每一个Watch通知回调创建线程.</span><br><span class="line">  controller broker 会为主题删除创建额外的I&#x2F;O线程.</span><br><span class="line">ReentrantLock同步机制</span><br><span class="line">  控制器通过大量的lock来同步访问共享的控制器缓存数据.</span><br><span class="line">0.11版本.</span><br><span class="line">  1.多线程模型  -&gt; 事件队列(访问修改控制器缓存数据的事件)&lt;&gt;单线程  +  多线程</span><br><span class="line">  2.zookeeper的同步操作改为异步操作. </span><br><span class="line">    tips: 当有大量主题分区变更时候,zookeeper容易成为系统的瓶颈.</span><br><span class="line">2.2版本.</span><br><span class="line">  kafka broker支持不同优先级请求处理 -&gt; 将控制器发来的请求与clien发来的请求分开.</span><br><span class="line">  tips: 如client 发了大量的Produce请求,控制器发了StopReplica请求,若Produce先执行,则无意义(因为stop请求删除了副本).</span><br></pre></td></tr></table></figure>
<h3 id="HW和LEO"><a href="#HW和LEO" class="headerlink" title="HW和LEO"></a>HW和LEO</h3><p><img src="/2020/02/07/kafka/hw.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kafka 水位.</span><br><span class="line">   水位与位置信息绑定,及由消息位移来表征的.</span><br><span class="line">高水位(HW)的作用.</span><br><span class="line">   1.已提交消息和未提交消息的分割线.</span><br><span class="line">     已提交消息可以被消费者消费.</span><br><span class="line">   2.帮助kafka完成副本同步.</span><br><span class="line">LEO.</span><br><span class="line">  tips: 若acks&#x3D;all&#x2F;-1 ,那么kafka producer将会等到所有follower 副本同步leader副本这条消息并更新leo完成.</span><br></pre></td></tr></table></figure>
<h4 id="高水位更新机制"><a href="#高水位更新机制" class="headerlink" title="高水位更新机制"></a>高水位更新机制</h4><p><img src="/2020/02/07/kafka/hw-broker-1.png" alt><br><img src="/2020/02/07/kafka/hw-broker-2.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tips: leader 副本  -&gt; leo 生产者写数据</span><br><span class="line">                   -&gt; hw  -&gt; minLeo (leader,follower1  leo,follower2 leo)</span><br><span class="line">                      hw -&gt; follower副本来同步数据的时候会带着其leo.</span><br><span class="line">      follower 副本 -&gt; leo 拉取leader的消息后更新</span><br><span class="line">                    -&gt; hw -&gt; min(leader hw,leo)</span><br><span class="line">                   tips: 副本重启时候leo会比leader hw小.</span><br></pre></td></tr></table></figure>
<h4 id="Leader-epoch"><a href="#Leader-epoch" class="headerlink" title="Leader epoch"></a>Leader epoch</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tips: leader副本的HW是在客户端下一次拉取时(上报leo)更新.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/hw-message-miss.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tips: 在上图所示的场景中,消息丢失主要为B服务器重启后,会进行日志截断操作,将大于B的高水位的消息全部截断掉.</span><br><span class="line">      A奔溃好了后,发现Bhw比自己leo大,进行日志截断操作.</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/07/kafka/hw-message-wrong.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tips: 这个场景也是日志截断导致的.</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka 0.11 -&gt; 新增leader epoch规避hw存在消息丢失场景 </span><br><span class="line">  重启后根据获取leader的&lt;epoch,offset&gt;,若my epoch&#x3D;&#x3D;leader epoch,则对myleo&gt;leader leo进行截取.若my epoch &lt; leader epoch &amp; my leo &gt;&#x3D; leader offset,则截取.</span><br></pre></td></tr></table></figure>
<h2 id="监控与管理"><a href="#监控与管理" class="headerlink" title="监控与管理"></a>监控与管理</h2><h3 id="主题管理"><a href="#主题管理" class="headerlink" title="主题管理"></a>主题管理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">删 -&gt; 删除操作是异步的.</span><br><span class="line">改 -&gt; 修改主题分区,修改主题级别参数,变更副本数,修改主题限速,主题分区迁移.</span><br><span class="line">查 -&gt; 查询主题列表,查询单个主题的详细数据.</span><br></pre></td></tr></table></figure>
<h4 id="kfaka-sh"><a href="#kfaka-sh" class="headerlink" title="kfaka-*.sh"></a>kfaka-*.sh</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">1.主题创建</span><br><span class="line">  kafka 2.2</span><br><span class="line">    bin&#x2F;kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</span><br><span class="line">  kafka 2.2之前</span><br><span class="line">    bin&#x2F;kafka-topics.sh --zookeeper $&#123;zookeeper&#125;:2181 --create --topic my_topic_name  --partitions 1 --replication-factor 1 </span><br><span class="line">  使用--zookeeper会绕过kafka安全体系.</span><br><span class="line">2.主题查询.</span><br><span class="line">  bin&#x2F;kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt;</span><br><span class="line">  bin&#x2F;kafka-topics.sh --zookeeper broker_host:port --describe --topic &lt;topic_name&gt;</span><br><span class="line">  tips: --bootstrap-server 会返回命令发起者能看到的主题.</span><br><span class="line">3.修改主题分区数(tips: 只能增加,不能删除).</span><br><span class="line">  bin&#x2F;kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;</span><br><span class="line">4.修改主题级别参数.</span><br><span class="line">  kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes&#x3D;10485760</span><br><span class="line">5.变更副本数.</span><br><span class="line">  1.创建json文件 -&gt; 分区和副本的mapping.</span><br><span class="line">    &#123;&quot;version&quot;:1, &quot;partitions&quot;:[</span><br><span class="line">     &#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]&#125;, </span><br><span class="line">      &#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,2,1]&#125;,</span><br><span class="line">      &#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0,2]&#125;,</span><br><span class="line">      &#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,2,0]&#125;,</span><br><span class="line">      ...</span><br><span class="line">      &#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1,2]&#125;</span><br><span class="line">    ]&#125;</span><br><span class="line">  kafka-reassign-partitions.sh</span><br><span class="line">    bin&#x2F;kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute</span><br><span class="line">6.修改主题限速.</span><br><span class="line">  follower 副本 同步 leader副本使用的带宽.</span><br><span class="line">  &#x2F;&#x2F; entity-name -&gt; broker id</span><br><span class="line">  kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.rate&#x3D;104857600,follower.replication.throttled.rate&#x3D;104857600&#39; --entity-type brokers --entity-name 0</span><br><span class="line">  &#x2F;&#x2F; replicas -&gt; 限速副本,*表示通配符.</span><br><span class="line">  kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config &#39;leader.replication.throttled.replicas&#x3D;*,follower.replication.throttled.replicas&#x3D;*&#39; --entity-type topics --entity-name test</span><br><span class="line">7.主题分区迁移.</span><br><span class="line">  kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic &lt;topic_name&gt;</span><br></pre></td></tr></table></figure>
<h4 id="特殊主题管理和运维"><a href="#特殊主题管理和运维" class="headerlink" title="特殊主题管理和运维"></a>特殊主题管理和运维</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.特殊主题.</span><br><span class="line">  __consumer_offsets    -&gt;    消费者位移主题</span><br><span class="line">  tips: kafka 0.11之前,__consumer_offsets的副本数 &#x3D; min(运行的broker台数,offsets.topic.replication.factor)</span><br><span class="line">        kafka 0.11,__consumer_offsets的副本数 &#x3D; offsets.topic.replication.factor</span><br><span class="line">  __transaction_state   -&gt;    事务主题</span><br><span class="line">2.特殊主题消息内容的读取.</span><br><span class="line">  &#x2F;&#x2F;查看消费者组提交的位移数据</span><br><span class="line">  kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</span><br><span class="line">  &#x2F;&#x2F;查看主题信息</span><br><span class="line">  --formatter kafka.coordinator.group.GroupMetadataManager\$GroupMetadataMessageFormatter&quot;</span><br></pre></td></tr></table></figure>
<h4 id="常见主题错误处理"><a href="#常见主题错误处理" class="headerlink" title="常见主题错误处理"></a>常见主题错误处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1.主题删除失败(现象-&gt;删除主题分区数据依然保存在硬盘上).</span><br><span class="line">  1.副本所在的broker宕机了(没收到kafka 控制器的删除消息请求).</span><br><span class="line">    tips: broker重启后,删除操作会自动恢复.</span><br><span class="line">  2.待删除主题的部分分区依然在执行迁移过程.</span><br><span class="line"> 强制删除方式(类似磁盘格式化操作).</span><br><span class="line">    1.手动删除 ZooKeeper 节点 &#x2F;admin&#x2F;delete_topics 下以待删除主题为名的 znode。</span><br><span class="line">    2.手动删除该主题在磁盘上的分区目录.</span><br><span class="line">    3.在 ZooKeeper 中执行 rmr  &#x2F;controller，触发 Controller 重选举，刷新 Controller 缓存。</span><br><span class="line">2.__consumer_offsets占用太多的磁盘.</span><br><span class="line">  jstack 查看kafka-log-cleaner-thread前缀的线程状态</span><br><span class="line">  tips: 这些线程是对位移主题做compact操作的.</span><br></pre></td></tr></table></figure>
<h3 id="重设消费者位移"><a href="#重设消费者位移" class="headerlink" title="重设消费者位移"></a>重设消费者位移</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">auto.offset.rest (失败策略)</span><br><span class="line">  earliest  -&gt; 消费者组在分区上有提交的位移时候,从提交的offset处开始消费.</span><br><span class="line">            -&gt; 消费者组在分区上没有提交的位移时候,从分区开始处消费.</span><br><span class="line">  latest    -&gt; 消费者组在分区上有提交的位移时候,从提交的offset处开始消费.</span><br><span class="line">            -&gt; 消费者组在分区上没有提交的位移时候,从分区最新位置处消费.</span><br><span class="line">  none      -&gt; 各分区都存在已提交的offset时，从offset后开始消费；</span><br><span class="line">               只要有一个分区不存在已提交的offset，则抛出异常</span><br><span class="line">                </span><br><span class="line">1.重设位移策略.</span><br><span class="line">  Earliest               -&gt;      将位移调整到当前最早位移处</span><br><span class="line">  Latest                 -&gt;      将位移调整到当前最新位移处</span><br><span class="line">  Current                -&gt;      从分区当前位置消费.(当消费者应用重启后,所有消费者接着上次的位置继续消费)</span><br><span class="line">  Specified-Offset(KafkaConsumer#seek-&gt;void seek(TopicPartition partition, long offset))</span><br><span class="line">                                 把位移调成指定位移</span><br><span class="line">  Shift-By-N             -&gt;      把位移调成当前位移+N处</span><br><span class="line">  DateTime               -&gt;      将位移调整到大于给定时间的位移处</span><br><span class="line">  Duration               -&gt;      将位移调整到当前时间指定间隔的位移处</span><br></pre></td></tr></table></figure>
<h4 id="消费者API设置"><a href="#消费者API设置" class="headerlink" title="消费者API设置"></a>消费者API设置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">consumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);</span><br><span class="line">consumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);</span><br><span class="line">1.Earliest.</span><br><span class="line">  try(final KafkaConsumer&lt;String, String&gt; consumer &#x3D;   new KafkaConsumer&lt;&gt;(consumerProperties))&#123;</span><br><span class="line">      consumer.subscribe(Collections.singleton(topic));</span><br><span class="line">      consumer.poll(0); &#x2F;&#x2F; 触发reblance,获取topicPartition</span><br><span class="line">      consumer.seekToBeginning(</span><br><span class="line">        consumer.partitionsFor(topic).stream()</span><br><span class="line">        .map(partition -&gt; new TopicPartition(topic,partionInfo.partition()))  </span><br><span class="line">        .collect(Collectors.toList());</span><br><span class="line">      )</span><br><span class="line">  &#125;</span><br><span class="line">2.Latest.</span><br><span class="line">  consumer.seekToEnd(</span><br><span class="line">    consumer.partitionsFor(topic).stream().map(partitionInfo -&gt;          </span><br><span class="line">    new TopicPartition(topic, partitionInfo.partition()))</span><br><span class="line">    .collect(Collectors.toList()));</span><br><span class="line">3.Current.</span><br><span class="line">  consumer.partitionsFor(topic).stream().map(info -&gt; </span><br><span class="line">    new TopicPartition(topic, info.partition()))</span><br><span class="line">    .forEach(tp -&gt; &#123;</span><br><span class="line">    long committedOffset &#x3D; consumer.committed(tp).offset();</span><br><span class="line">    consumer.seek(tp, committedOffset);</span><br><span class="line">  &#125;);</span><br><span class="line">4.Specified-Offset.</span><br><span class="line">  long targetOffset &#x3D; 1234L;</span><br><span class="line">  for (PartitionInfo info : consumer.partitionsFor(topic)) &#123;</span><br><span class="line">    TopicPartition tp &#x3D; new TopicPartition(topic, info.partition());</span><br><span class="line">    consumer.seek(tp, targetOffset);</span><br><span class="line">  &#125;</span><br><span class="line">5.DateTime.</span><br><span class="line">  long ts &#x3D; LocalDateTime.of(2019, 6, 20, 20, 0)</span><br><span class="line">            .toInstant(ZoneOffset.ofHours(8)).toEpochMilli();</span><br><span class="line">  Map&lt;TopicPartition, Long&gt; timeToSearch &#x3D; </span><br><span class="line">           consumer.partitionsFor(topic).stream()</span><br><span class="line">           .map(info -&gt;new TopicPartition(topic, info.partition()))</span><br><span class="line">           &#x2F;&#x2F; 将topicPartition 转成 Map&lt;TopicPartition,Long&gt;</span><br><span class="line">           .collect(Collectors.toMap(Function.identity(), tp -&gt; ts));</span><br><span class="line">  for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : consumer.offsetsForTimes(timeToSearch).entrySet()) &#123;</span><br><span class="line">    consumer.seek(entry.getKey(), entry.getValue().offset());</span><br><span class="line">  &#125;</span><br><span class="line">6.Duration策略.</span><br><span class="line">  Map&lt;TopicPartition, Long&gt; timeToSearch &#x3D; consumer.partitionsFor(topic).stream()</span><br><span class="line">           .map(info -&gt; new TopicPartition(topic, info.partition()))</span><br><span class="line">           .collect(Collectors.toMap(Function.identity(), tp -&gt; System.currentTimeMillis() - 30 * 1000  * 60));</span><br><span class="line"></span><br><span class="line">  for (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : </span><br><span class="line">           consumer.offsetsForTimes(timeToSearch).entrySet()) &#123;</span><br><span class="line">           consumer.seek(entry.getKey(), entry.getValue().offset());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="Kafka监控"><a href="#Kafka监控" class="headerlink" title="Kafka监控"></a>Kafka监控</h3><h4 id="主机监控"><a href="#主机监控" class="headerlink" title="主机监控"></a>主机监控</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">机器负载(load) -&gt; cpu使用的数量</span><br><span class="line">cpu使用时间 -&gt; 1s内 cpu使用时间 </span><br><span class="line">cpu使用率 -&gt;cpu使用时间&#x2F;1s,top指令.</span><br><span class="line">  tips:top指令查看的cpu使用率是所有cpu核数的和,如4核-&gt;50%,1核12%.</span><br><span class="line">内存指令 -&gt; 空闲内存,已使用内存(free指令)</span><br><span class="line">磁盘I&#x2F;O使用率 &#x2F; IOPS</span><br><span class="line">网络I&#x2F;O使用率</span><br><span class="line">TCP连接数</span><br><span class="line">打开文件数</span><br><span class="line">inode使用情况</span><br></pre></td></tr></table></figure>
<h4 id="jvm监控-broker-进程"><a href="#jvm监控-broker-进程" class="headerlink" title="jvm监控 - broker 进程"></a>jvm监控 - broker 进程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">堆,新生代,老年代大小.</span><br><span class="line">GC回收器.</span><br><span class="line">Minor GC &#x2F; Full GC 发生频率和时长.</span><br><span class="line">线程状态&#x2F;总数.</span><br><span class="line">活跃对象(存活对象)大小  -&gt; 设置堆大小的重要依据.</span><br><span class="line">gc日志 -&gt; kafkaserver-gc.log</span><br></pre></td></tr></table></figure>
<h4 id="集群监控"><a href="#集群监控" class="headerlink" title="集群监控"></a>集群监控</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">1.broker端日志.</span><br><span class="line">  1.server.log.</span><br><span class="line">  2.controller.log.</span><br><span class="line">  3.state-change.log.</span><br><span class="line">2.broker端关键线程的运行状态.</span><br><span class="line">  log compaction -&gt; 做日志Compaction.</span><br><span class="line">    挂了导致__consumer__offset的日志越来越大</span><br><span class="line">  ReplicaFetcherThread -&gt; 分区副本想向leader副本拉取消息的线程.</span><br><span class="line">    follower副本的lag会越来越大.</span><br><span class="line">3.broker端jmx指标.</span><br><span class="line">  1.BytesIn&#x2F;BytesOut -&gt; broker端每秒入站和出站的字节数,注意控制指标值要低于网络带宽.</span><br><span class="line">  2.NetworkProcessorAvgIdlePercent -&gt; 即网络线程池线程平均的空闲比例。</span><br><span class="line">    这个是空闲比例不是使用比例.</span><br><span class="line">  3.RequestHandlerAvgIdlePercent  -&gt;  I&#x2F;O线程池空闲比例.</span><br><span class="line">  4.UnderReplicatedPartitions  -&gt;  即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步,一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失.</span><br><span class="line">  5.ISRShrink&#x2F;ISRExpand  -&gt;   ISR 收缩和扩容的频次指标.</span><br><span class="line">  6.ActiveControllerCount -&gt;  当前处于激活状态的控制器的数量.</span><br><span class="line">    tips: 若ActiveControllerCount为2,则说明出现了脑裂问题.</span><br><span class="line">          脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。</span><br></pre></td></tr></table></figure>
<h4 id="kafka客户端"><a href="#kafka客户端" class="headerlink" title="kafka客户端"></a>kafka客户端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.RTT(Round-Trip time)  -&gt; 网络往返时延. 可以通过ping指令查看rtt是多少.</span><br><span class="line">2.线程.</span><br><span class="line">  kafka-producer-network-thread -&gt; 消息发送线程</span><br><span class="line">  kafka-coordinator-heartbeat-thread -&gt; 消费者心跳线程</span><br><span class="line">3.JMX.</span><br><span class="line">  producer -&gt; request-latency - 消息生产请求的延时</span><br><span class="line">  consumer -&gt; records-leg,records-lead.</span><br><span class="line">           -&gt; join rate,sync rate - reblance的频繁比例.</span><br><span class="line">              reblance还可以通过日志看,再均衡时有个generation表示是第几次Reblance.</span><br></pre></td></tr></table></figure>





















    </div>

    
    
    
		<div>
			
				<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

			
		</div>

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/java/" rel="tag"># java</a>
              <a href="/tags/kafka/" rel="tag"># kafka</a>
              <a href="/tags/messaging/" rel="tag"># messaging</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/06/Spike-system/" rel="prev" title="Spike-system">
      <i class="fa fa-chevron-left"></i> Spike-system
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/10/nosql/" rel="next" title="nosql">
      nosql <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="comments"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka入门"><span class="nav-number">1.</span> <span class="nav-text">kafka入门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#消息引擎系统"><span class="nav-number">1.1.</span> <span class="nav-text">消息引擎系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka术语"><span class="nav-number">1.2.</span> <span class="nav-text">kafka术语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka为啥这么快"><span class="nav-number">1.3.</span> <span class="nav-text">kafka为啥这么快</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka版本迭代"><span class="nav-number">1.4.</span> <span class="nav-text">kafka版本迭代</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka基本使用"><span class="nav-number">2.</span> <span class="nav-text">kafka基本使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#linux操作系统"><span class="nav-number">2.1.</span> <span class="nav-text">linux操作系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka-broker-参数配置"><span class="nav-number">2.2.</span> <span class="nav-text">kafka broker 参数配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#broker端参数"><span class="nav-number">2.2.1.</span> <span class="nav-text">broker端参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#broker连接参数"><span class="nav-number">2.2.2.</span> <span class="nav-text">broker连接参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#zookeeper配置"><span class="nav-number">2.2.3.</span> <span class="nav-text">zookeeper配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#topic管理"><span class="nav-number">2.2.4.</span> <span class="nav-text">topic管理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据留存方面"><span class="nav-number">2.2.5.</span> <span class="nav-text">数据留存方面</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#topic级别参数"><span class="nav-number">2.2.6.</span> <span class="nav-text">topic级别参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#JVM参数"><span class="nav-number">2.2.7.</span> <span class="nav-text">JVM参数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#操作系统参数"><span class="nav-number">2.2.8.</span> <span class="nav-text">操作系统参数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#客户端实践及原理剖析"><span class="nav-number">3.</span> <span class="nav-text">客户端实践及原理剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么分区"><span class="nav-number">3.1.</span> <span class="nav-text">为什么分区</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生产者压缩算法"><span class="nav-number">3.2.</span> <span class="nav-text">生产者压缩算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#无消息丢失配置"><span class="nav-number">3.3.</span> <span class="nav-text">无消息丢失配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#客户端高级功能-不常用"><span class="nav-number">3.4.</span> <span class="nav-text">客户端高级功能(不常用)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拦截器"><span class="nav-number">3.4.1.</span> <span class="nav-text">拦截器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#java生产者管理tcp连接"><span class="nav-number">3.4.2.</span> <span class="nav-text">java生产者管理tcp连接</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#幂等生产者和事务"><span class="nav-number">3.5.</span> <span class="nav-text">幂等生产者和事务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#幂等性"><span class="nav-number">3.5.1.</span> <span class="nav-text">幂等性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#事务"><span class="nav-number">3.5.2.</span> <span class="nav-text">事务</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费者组"><span class="nav-number">3.6.</span> <span class="nav-text">消费者组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka-新版本位移存储"><span class="nav-number">3.7.</span> <span class="nav-text">kafka 新版本位移存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Coordinator-协调者"><span class="nav-number">3.8.</span> <span class="nav-text">Coordinator(协调者)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka位移提交"><span class="nav-number">3.9.</span> <span class="nav-text">kafka位移提交</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CommitFailedException"><span class="nav-number">3.10.</span> <span class="nav-text">CommitFailedException</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多线程开发消费者实例"><span class="nav-number">3.11.</span> <span class="nav-text">多线程开发消费者实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Java消费者如何管理TCP连接"><span class="nav-number">3.12.</span> <span class="nav-text">Java消费者如何管理TCP连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费者组消费进度监控"><span class="nav-number">3.13.</span> <span class="nav-text">消费者组消费进度监控</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深入kafka内核"><span class="nav-number">4.</span> <span class="nav-text">深入kafka内核</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka副本机制详解"><span class="nav-number">4.1.</span> <span class="nav-text">kafka副本机制详解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ISR"><span class="nav-number">4.1.1.</span> <span class="nav-text">ISR</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka-请求处理"><span class="nav-number">4.2.</span> <span class="nav-text">kafka 请求处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消费者组Reblance"><span class="nav-number">4.3.</span> <span class="nav-text">消费者组Reblance</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#触发时机"><span class="nav-number">4.3.1.</span> <span class="nav-text">触发时机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费端对reblance的感知"><span class="nav-number">4.3.2.</span> <span class="nav-text">消费端对reblance的感知</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者状态机"><span class="nav-number">4.3.3.</span> <span class="nav-text">消费者状态机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者端重平衡流程"><span class="nav-number">4.3.4.</span> <span class="nav-text">消费者端重平衡流程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka控制器"><span class="nav-number">4.4.</span> <span class="nav-text">kafka控制器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#控制器故障转移-failover"><span class="nav-number">4.4.1.</span> <span class="nav-text">控制器故障转移(failover)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#控制器内部设计原理"><span class="nav-number">4.4.2.</span> <span class="nav-text">控制器内部设计原理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HW和LEO"><span class="nav-number">4.5.</span> <span class="nav-text">HW和LEO</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#高水位更新机制"><span class="nav-number">4.5.1.</span> <span class="nav-text">高水位更新机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-epoch"><span class="nav-number">4.5.2.</span> <span class="nav-text">Leader epoch</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监控与管理"><span class="nav-number">5.</span> <span class="nav-text">监控与管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主题管理"><span class="nav-number">5.1.</span> <span class="nav-text">主题管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kfaka-sh"><span class="nav-number">5.1.1.</span> <span class="nav-text">kfaka-*.sh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特殊主题管理和运维"><span class="nav-number">5.1.2.</span> <span class="nav-text">特殊主题管理和运维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#常见主题错误处理"><span class="nav-number">5.1.3.</span> <span class="nav-text">常见主题错误处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#重设消费者位移"><span class="nav-number">5.2.</span> <span class="nav-text">重设消费者位移</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#消费者API设置"><span class="nav-number">5.2.1.</span> <span class="nav-text">消费者API设置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka监控"><span class="nav-number">5.3.</span> <span class="nav-text">Kafka监控</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#主机监控"><span class="nav-number">5.3.1.</span> <span class="nav-text">主机监控</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#jvm监控-broker-进程"><span class="nav-number">5.3.2.</span> <span class="nav-text">jvm监控 - broker 进程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#集群监控"><span class="nav-number">5.3.3.</span> <span class="nav-text">集群监控</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kafka客户端"><span class="nav-number">5.3.4.</span> <span class="nav-text">kafka客户端</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="vicyor"
      src="/images/head.png">
  <p class="site-author-name" itemprop="name">vicyor</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">55</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">49</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/vicyor" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vicyor" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2457569580@qq.com" title="E-Mail → mailto:2457569580@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">vicyor</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">885k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">13:25</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.6.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = visitors.getAttribute('id').trim();
      var title = visitors.getAttribute('data-flag-title').trim();

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.log('Failed to save visitor count', error);
              })
          } else {
              Counter('post', '/classes/Counter', { title: title, url: url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.log('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return element.getAttribute('id').trim();
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.log('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=m9GqFbk5NEr9mLiLAXCyheul-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'm9GqFbk5NEr9mLiLAXCyheul-gzGzoHsz',
            'X-LC-Key': 'g7WSuE6aDmunoX4rgyBN7SJa',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.getScript('//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'qQhr9rNGJh6YalJA0mfaaurx-gzGzoHsz',
    appKey: 'kJy8NJeOTMPnxQ3zLihOcnw3',
    placeholder: "请留下您的宝贵评论",
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script>

	
		 <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas> 
		 <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script> 
		 <script type="text/javascript" src="/js/src/fireworks.js"></script>
	
</body>
</html>
